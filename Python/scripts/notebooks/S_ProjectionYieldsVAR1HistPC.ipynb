{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script projects the swap curve assuming that 6 key shadow rates\n",
    "follow a VAR[1-1]/MVOU process and modeling the invariants non\n",
    "parametrically through the Historical with Flexible Probabilities\n",
    "distribution of the first three principal components.\n",
    "Projection is performed via the scenario-based approach,\n",
    "resampling from the HFP distribution of the invariants.\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-icvar-1-pc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from numpy.linalg import eig\n",
    "from numpy.ma import where\n",
    "from scipy.linalg import expm\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "\n",
    "from numpy import mean, r_, tile, sum as npsum, min as npmin, max as npmax, diff, percentile, newaxis\n",
    "\n",
    "from matplotlib.pyplot import figure, plot, axis, grid\n",
    "\n",
    "from HistogramFP import HistogramFP\n",
    "from numpy import arange, log, exp, array, zeros, ones\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import title, xlabel, ylabel\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from ARPM_utils import struct_to_dict, save_plot\n",
    "from InverseCallTransformation import InverseCallTransformation\n",
    "from intersect_matlab import intersect\n",
    "from RollPrices2YieldToMat import RollPrices2YieldToMat\n",
    "from FitVAR1 import FitVAR1\n",
    "from VAR1toMVOU import VAR1toMVOU\n",
    "from MinRelEntFP import MinRelEntFP\n",
    "from PerpetualAmericanCall import PerpetualAmericanCall\n",
    "from SampleScenProbDistribution import SampleScenProbDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load database db_SwapCurve and compute the realized time series of weekly rates for the key points of the curve with tau= [1 2 3 5 7 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_SwapCurve'),squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_SwapCurve'),squeeze_me=True)\n",
    "\n",
    "DF_Rolling = struct_to_dict(db['DF_Rolling'])\n",
    "\n",
    "tau=array([1, 2, 3, 5, 7, 10]) #time to maturity (years)\n",
    "_, _, tauIndices = intersect(tau,DF_Rolling.TimeToMat)\n",
    "timeStep=5 #weekly observations\n",
    "y,_ = RollPrices2YieldToMat(tau, DF_Rolling.Prices[tauIndices,::timeStep])\n",
    "dates=DF_Rolling.Dates[1::timeStep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the corresponding shadow rates, using function InverseCallTransformation with eta=0.013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta=0.013\n",
    "x=InverseCallTransformation(y, {1:eta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the time series of the realized invariants: fit the VAR[1-1]/MVOU model using functions FitVAR1 and VAR1toMVOU and compute the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quest for invariance: VAR(2)/MVOU fit')\n",
    "#dx=diff(x,1,2) #increments\n",
    "#t_=dx.shape[1]\n",
    "t_=diff(x,1,1).shape[1]\n",
    "\n",
    "#[mu, theta, sigma2] = FitVAR1MVOU(dx, x(:,1:-1), 1)\n",
    "[alpha, b, sig2_U] = FitVAR1(x)\n",
    "#[alpha, b, sig2_U] = FitVAR1(dx, x(:,1:-1))\n",
    "mu, theta, sigma2,_= VAR1toMVOU(alpha, b, sig2_U, 1)\n",
    "epsi = x[:,1:] - (expm(-theta)@x[:,:-1])-tile(mu[...,newaxis], (1,t_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction: consider the first l_ principal components and compute their HFP distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimension reduction/Estimation: HFP distribution of the first l_ principal components')\n",
    "# Eigenvalues and eigenvectors\n",
    "lamda2,e=eig(sigma2)\n",
    "l2=lamda2\n",
    "\n",
    "# Historical scenarios for Z\n",
    "k_=len(tau)\n",
    "l_=1 #number of principal components to take into account (l_=1 is set for speed set l_=3 for accurate results)\n",
    "z=e.T@epsi\n",
    "z=z[:l_,:] #historical scenarios\n",
    "\n",
    "#determine the Flexible Probabilities via Entropy Pooling starting from an exponential decay prior\n",
    "\n",
    "# Prior: exponential decay\n",
    "half_life=52*2 #2years\n",
    "prior_decay=log(2)/half_life\n",
    "p_=exp(-prior_decay*arange(t_,1+-1,-1)).reshape(1,-1)\n",
    "p_=p_/npsum(p_)\n",
    "\n",
    "# Entropy pooling\n",
    "#stretched variances\n",
    "v=l2*(npsum(l2)/npsum(l2[:l_]))\n",
    "\n",
    "p = zeros((l_,p_.shape[1]))\n",
    "for k in range(l_):\n",
    "    # constraints\n",
    "    Aeq=r_[z[[k],:]**2, ones((1,t_))]\n",
    "    beq=array([[v[k]], [1]])\n",
    "    p[k,:]= MinRelEntFP(p_, None, None, Aeq, beq)[0] #Flexible Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project paths for the risk drivers:\n",
    "## resample scenarios for the invariants from the principal components' HFP distribution and feed them into the incremental step projection routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Projection')\n",
    "u_end = 2*52 #max horizon = 2y\n",
    "u=range(u_end) #projection to weekly horizons up to u_\n",
    "\n",
    "j_ = 5000 #number of resampled scenarios\n",
    "\n",
    "X_u = zeros((x.shape[0],j_,len(u)+1))\n",
    "X_u[:,:,0]=tile(x[:,[-1]],(1,j_))\n",
    "\n",
    "zsim = zeros((l_,j_,len(u)+1))\n",
    "Epsi = zeros((k_,j_,len(u)+1))\n",
    "\n",
    "for hor in u:\n",
    "    # Generate MC simulations for the principal components\n",
    "    for k in range(l_):\n",
    "        zsim[k,:,hor+1]=SampleScenProbDistribution(z[[k],:],p[[k],:],j_)\n",
    "    \n",
    "    # Obtain scenarios for the invariants from the PC scenarios\n",
    "    Epsi[:,:,hor+1]=e[:,:l_]@zsim[:,:,hor+1]\n",
    "    # Obtain paths for the risk drivers (shadow rates) from the invariants' scenarios\n",
    "    X_u[:,:,hor+1]=expm(-theta)@X_u[:,:,hor]+ tile(mu[...,newaxis], (1, j_))+Epsi[:,:,hor+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the projected risk drivers into the projected term structure of swap rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_u=zeros(X_u.shape)\n",
    "Y_u[:,:,0]=tile(y[:,[-1]],(1,j_))\n",
    "for hor in u:\n",
    "    for k in range(k_):\n",
    "        Y_u[k,:,hor+1]=PerpetualAmericanCall(X_u[k,:,hor+1].T,{'eta':eta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the projected distribution of the 5 years yield along with a few simulated paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick=where(tau==5)[0] # select the 5-year yield\n",
    "ps=[1, 99] #quantile levels for the plot\n",
    "\n",
    "p_flat = ones((1, Y_u[pick,:,0].shape[1])) / Y_u[pick,:,0].shape[1]\n",
    "Y = namedtuple('Y','x pdf q m')\n",
    "Y.x=zeros((1,81))\n",
    "Y.pdf=zeros((1,80))\n",
    "Y.q=zeros((1,2))\n",
    "Y.m=[]\n",
    "option = namedtuple('option','n_bins')\n",
    "for i in range(u_end+1):\n",
    "    option.n_bins = 80\n",
    "    pdf,xx = HistogramFP(Y_u[pick,:,i], p_flat, option)\n",
    "    q=percentile(Y_u[pick,:,i],ps) # quantiles\n",
    "    m=mean(Y_u[pick,:,i]) #mean\n",
    "    Y.x=r_[Y.x, xx.reshape(1,-1)]\n",
    "    Y.pdf=r_[Y.pdf, pdf]\n",
    "    Y.q=r_[Y.q, q.reshape(1,-1)]\n",
    "    Y.m=r_[Y.m, m]\n",
    "\n",
    "Y.pdf = Y.pdf[1:]\n",
    "Y.x = Y.x[1:]\n",
    "Y.q = Y.q[1:]\n",
    "\n",
    "# figure\n",
    "y0= y[pick,-1]\n",
    "figure()\n",
    "plot(arange(0,u_end+1),Y.q,color='r')\n",
    "plot(arange(0,u_end+1),Y.m,color='g')\n",
    "plot(arange(0,u_end+1), Y_u[pick,:10,:].squeeze().T,c=[.7, .7, .7],lw=1)\n",
    "xx=r_[u_end,  u_end+Y.pdf[-2]*0.5,  u_end]\n",
    "yy=r_[npmin(Y.x[-2]), Y.x[-2,:-1], npmax(Y.x[-2])]\n",
    "plot(xx,yy,'k',lw=1)\n",
    "plt.gca().fill_between(xx,yy,color=[.7, .7, .7])\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda z,_: '{:.0%}'.format(z)))\n",
    "axis([0, npmax(xx)*1.1, 0, 0.05])\n",
    "grid(True)\n",
    "plt.xticks(arange(0,u_end+1,52),[0, 1, 2])\n",
    "title('Projection of the 5yr par swap rates')\n",
    "xlabel('projection horizon (years)')\n",
    "ylabel('yields');\n",
    "plt.show()\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_BootstrapSPX [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_BootstrapSPX&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-hist-boot-proj-vue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange, zeros, argsort, diff, abs, log, exp, sqrt, tile, r_\n",
    "from numpy import sum as npsum\n",
    "\n",
    "from scipy.stats import t as tstu\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from intersect_matlab import intersect\n",
    "from ConditionalFP import ConditionalFP\n",
    "from MaxLikelihoodFPLocDispT import MaxLikelihoodFPLocDispT\n",
    "from SampleScenProbDistribution import SampleScenProbDistribution\n",
    "\n",
    "def struct_to_dict(s, as_namedtuple=True):\n",
    "    if as_namedtuple:\n",
    "        if s.dtype.names:\n",
    "            nt = namedtuple('db', s.dtype.names)\n",
    "            d = {}\n",
    "            for x in s.dtype.names:\n",
    "                try:\n",
    "                    if x in ['Parameters','marginalt','DCCfit']:\n",
    "                        d[x] = struct_to_dict(s[x])\n",
    "                    elif isinstance(s[x], np.ndarray):\n",
    "                        if x == 'sig2':\n",
    "                            d[x] = s[x][0]\n",
    "                        else:\n",
    "                            d[x] = s[x]\n",
    "                    else:\n",
    "                        d[x] = np.atleast_1d(s[x]).flatten()[0]\n",
    "                except:\n",
    "                    d[x] = None\n",
    "            nt = nt(**d)\n",
    "            return nt\n",
    "    else:\n",
    "        if s.dtype.names:\n",
    "            return {x: np.atleast_1d(s[x]).flatten()[0] for x in s.dtype.names}\n",
    "\n",
    "# parameters\n",
    "tauHL_smoo = 30  # half-life time for smoothing\n",
    "tauHL_scor = 100  # half-life time for scoring\n",
    "\n",
    "alpha = 0.25\n",
    "tauHL_prior = 21*4  # parameters for Flexible Probabilities conditioned on VIX\n",
    "\n",
    "nu_vec = arange(2,31)\n",
    "nu_ = len(nu_vec)\n",
    "\n",
    "j_ = 100  # number of scenarios of projected invariants\n",
    "m_ = 500  # number of monitoring times in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this database is created by VUEscript\n",
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_SPX_zcb_Invariants'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_SPX_zcb_Invariants'), squeeze_me=True)\n",
    "\n",
    "dates = db['dates']\n",
    "epsi_SPX = db['epsi_SPX']\n",
    "\n",
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_VIX'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_VIX'), squeeze_me=True)\n",
    "\n",
    "from ARPM_utils import struct_to_dict\n",
    "\n",
    "VIX = struct_to_dict(db['VIX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover the time series of realized invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIX's compounded returns\n",
    "c_VIX = diff(log(VIX.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the time series of the conditioning variable by applying sequentially smoothing and scoring filters to the time series of VIX's compounded returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vix = len(c_VIX)\n",
    "times = arange(t_vix)\n",
    "\n",
    "# smoothing\n",
    "z_vix = zeros((1, t_vix))\n",
    "for it in range(t_vix):\n",
    "    p_smoo_t = exp(-log(2) / tauHL_smoo * (tile(it + 1, (1, it + 1)) - times[:it + 1]))\n",
    "    gamma_t = npsum(p_smoo_t)\n",
    "    z_vix[0, it] = npsum(p_smoo_t * c_VIX[:it + 1]) / gamma_t\n",
    "\n",
    "# scoring\n",
    "mu_hat = zeros((1, t_vix))\n",
    "mu2_hat = zeros((1, t_vix))\n",
    "sd_hat = zeros((1, t_vix))\n",
    "for t in range(t_vix):\n",
    "    p_scor_t = exp(-log(2) / tauHL_scor*(tile(t+1, (1, t+1))-times[:t+1]))\n",
    "    gamma_scor_t = npsum(p_scor_t)\n",
    "    mu_hat[0,t] = npsum(p_scor_t * z_vix[0,:t+1]) / gamma_scor_t\n",
    "    mu2_hat[0,t] = npsum(p_scor_t * (z_vix[0,:t+1])**2) / gamma_scor_t\n",
    "    sd_hat[0,t] = sqrt(mu2_hat[0,t]-(mu_hat[0,t])**2)\n",
    "\n",
    "z_vix = (z_vix - mu_hat) / sd_hat\n",
    "dates_zvix=VIX.Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the time series of invariants with the time series of the conditioning variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_SPX, tau_vix, tau_SPX = intersect(VIX.Date, dates)\n",
    "z_vix_cond=z_vix[[0],tau_vix].reshape(1,-1)\n",
    "epsi_SPX=epsi_SPX[tau_SPX].reshape(1,-1)\n",
    "i_, t_ = epsi_SPX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the state and time conditioning probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vix_star = z_vix_cond[[0],-1]  # target value\n",
    "prior = exp((-(log(2) / tauHL_prior))*abs(arange(t_, 1 + -1, -1)))\n",
    "prior = prior / npsum(prior)\n",
    "# conditioner\n",
    "conditioner = namedtuple('conditioner', 'Series TargetValue Leeway')\n",
    "conditioner.Series = z_vix_cond\n",
    "conditioner.TargetValue = np.atleast_2d(z_vix_star)\n",
    "conditioner.Leeway = alpha\n",
    "p = ConditionalFP(conditioner, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the marginal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_marg_SPX = zeros(i_)\n",
    "mu_marg_SPX = zeros(i_)\n",
    "sig2_marg_SPX = zeros(i_)\n",
    "for i in range(i_):\n",
    "    mu_nu = zeros(nu_)\n",
    "    sig2_nu = zeros(nu_)\n",
    "    like_nu = zeros(nu_)\n",
    "    for k in range(nu_):\n",
    "        nu = nu_vec[k]\n",
    "        mu_nu[k], sig2_nu[k],_ = MaxLikelihoodFPLocDispT(epsi_SPX[[i],:], p, nu, 10 ** -6, 1)\n",
    "        epsi_t = (epsi_SPX[i, :] - mu_nu[k]) / sqrt(sig2_nu[k])\n",
    "        like_nu[k] = npsum(p * log(tstu.pdf(epsi_t, nu) / sqrt(sig2_nu[k])))\n",
    "\n",
    "    k_nu = argsort(like_nu)[::-1]\n",
    "    nu_marg_SPX[i] = max(nu_vec[k_nu[0]], 10)\n",
    "    mu_marg_SPX[i] = mu_nu[k_nu[0]]\n",
    "    sig2_marg_SPX[i] = sig2_nu[k_nu[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the historical distribution of the invariants' copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_SPX = zeros((i_, t_))\n",
    "for i in range(i_):\n",
    "    u_SPX[i,:]=tstu.cdf((epsi_SPX[i, :] - mu_marg_SPX[i]) / sqrt(sig2_marg_SPX[i]), nu_marg_SPX[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the grades' projected paths scenarios via historical bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_SPX_hor = zeros((i_, m_, j_))\n",
    "for m in range(m_):\n",
    "    U_boot= SampleScenProbDistribution(u_SPX, p, j_)\n",
    "    U_SPX_hor[:,m,:] = U_boot.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the projected path scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epsi_SPX_hor = zeros((i_, m_, j_))\n",
    "for i in range(i_):\n",
    "    for m in range(m_):\n",
    "        Epsi_SPX_hor[i, m,:]=mu_marg_SPX[i] + sqrt(sig2_marg_SPX[i])*tstu.ppf(U_SPX_hor[i, m,:], nu_marg_SPX[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_to_save = ['nu_marg_SPX', 'mu_marg_SPX', 'sig2_marg_SPX', 'U_SPX_hor', 'epsi_SPX_hor', 'epsi_SPX', 'dates_SPX', 'z_vix', 'dates_zvix']\n",
    "vars_to_save = {varname: var for varname, var in locals().items() if isinstance(var,(np.ndarray,np.float,np.int))}\n",
    "vars_to_save = {varname: var for varname, var in vars_to_save.items() if varname in varnames_to_save}\n",
    "savemat(os.path.join(TEMPORARY_DB,'db_HistBootstrappingProj'),vars_to_save)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_bias_reduction_toy [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_bias_reduction_toy&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin\n",
    "import matplotlib.pyplot as plt\n",
    "from arpym.statistics.simulate_normal import simulate_normal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.zeros(2)\n",
    "sigma2 = np.array([[1, 0.5], [0.5, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 0](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy-implementation-step00): Generate sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "xz = simulate_normal(mu, sigma2, 10**6)\n",
    "xz = 10**-3 + np.exp(xz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy-implementation-step01): Define predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_theta = lambda theta, z: theta[0] + theta[1]*z\n",
    "f_theta = lambda theta, x, z: theta*z*np.exp(-theta*x*z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy-implementation-step02): Compute point bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_point = np.array([np.exp(0.5)*(1-(np.exp(0.5)-1)/(np.exp(1)-1)), (np.exp(0.5)-1)/(np.exp(1)-1)])\n",
    "print(theta_point)\n",
    "err_point = np.mean((xz[:, 0]-(theta_point[0]+theta_point[1]*xz[:,1]))**2)\n",
    "\n",
    "true_point_pred = lambda z : np.exp(0.375)*np.sqrt(z)\n",
    "true_err_point = np.mean((xz[:, 0]- true_point_pred(xz[:, 1]))**2)\n",
    "\n",
    "bias_point = err_point-true_err_point\n",
    "print(bias_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy-implementation-step03): Compute probabilistic bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_prob = np.linspace(10**-2, 5, 10**2)\n",
    "err_prob = np.zeros(len(theta_prob))\n",
    "\n",
    "for i in range(len(theta_prob)):\n",
    "    err_prob[i] = np.mean(-np.log(f_theta(theta_prob[i], xz[:,0], xz[:,1])))\n",
    "\n",
    "# Optimal theta\n",
    "theta_prob_opt = theta_prob[np.argmin(err_prob)]\n",
    "print(theta_prob_opt)\n",
    "\n",
    "# Optimal error\n",
    "err_prob_opt = np.min(err_prob)\n",
    "bias_prob = err_prob_opt\n",
    "print(bias_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy-implementation-step04): Add interactions to point prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_theta_inter = lambda theta, z: theta[0] + theta[1]*z + theta[2]*z**2\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "z_inter = poly.fit_transform(xz[:, [1]])\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression(fit_intercept=False).fit(z_inter, xz[:, 0])\n",
    "theta_point_inter = reg.coef_\n",
    "print(theta_point_inter)\n",
    "\n",
    "err_point_inter = np.mean((xz[:, 0]-(theta_point_inter[0]+theta_point_inter[1]*xz[:,1]+theta_point_inter[2]*xz[:,1]**2))**2)\n",
    "\n",
    "bias_point_inter = err_point_inter - err_point\n",
    "print(bias_point_inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 5](https://www.arpm.co/lab/redirect.php?permalink=s_bias_reduction_toy-implementation-step05): Add interactions to probabilistic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_theta_inter = lambda theta, x, z: (theta[0]*z + theta[1]*z**2)*np.exp(-x*(theta[0]*z + theta[1]*z**2))\n",
    "\n",
    "f_min = lambda theta : np.mean(-np.log(f_theta_inter(theta, xz[:,0], xz[:,1])))\n",
    "\n",
    "# Optimal theta\n",
    "theta_prob_opt_inter = fmin(f_min, [0.2, -10**-3])\n",
    "print(theta_prob_opt_inter)\n",
    "\n",
    "# Optimal error\n",
    "err_prob_opt_inter = f_min(theta_prob_opt_inter)\n",
    "\n",
    "bias_prob_inter = err_prob_opt_inter\n",
    "print(bias_prob_inter)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_linclass_regression [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_linclass_regression&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=s_linclass_regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from arpym.statistics.simulate_normal import simulate_normal\n",
    "from arpym.tools.logo import add_logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_linclass_regression-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "j_ = 5000  #number of simulations\n",
    "mu_z = np.zeros(2)  # expectation\n",
    "sigma2_z = np.array([[1, 0], [0, 1]])  # covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_linclass_regression-implementation-step01): Define features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def muf(z1, z2):\n",
    "    return z1 - np.tanh(10*z1*z2)\n",
    "\n",
    "\n",
    "def sigf(z1, z2):\n",
    "    return np.sqrt(np.minimum(z1**2, 1/(10*np.pi)))\n",
    "\n",
    "\n",
    "z = simulate_normal(mu_z, sigma2_z, j_)  # scenarios of features\n",
    "psi_z = np.c_[z[:, 0], z[:, 0]*z[:, 1]]\n",
    "x = muf(z[:, 0], z[:, 1]) +\\\n",
    "       sigf(z[:, 0], z[:, 1]) * simulate_normal(0, 1, j_) # scenarios of target variables\n",
    "\n",
    "x = np.heaviside(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_linclass_regression-implementation-step02): Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "x_enc = enc.fit_transform(np.atleast_2d(x).T).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_linclass_regression-implementation-step03): Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg = lin_reg.fit(psi_z, x_enc)\n",
    "\n",
    "beta_1hot = lin_reg.coef_ \n",
    "alpha_1hot = lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4](https://www.arpm.co/lab/redirect.php?permalink=s_linclass_regression-implementation-step04): Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = beta_1hot[1, :]-beta_1hot[0, :]\n",
    "alpha = alpha_1hot[1]-alpha_1hot[0]\n",
    "\n",
    "\n",
    "def chi_alphabeta(z):\n",
    "    return np.heaviside(alpha + z@beta.T, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 5](https://www.arpm.co/lab/redirect.php?permalink=s_linclass_regression-implementation-step05): Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = chi_alphabeta(psi_z)\n",
    "\n",
    "# Probabilities\n",
    "p_class = expit(alpha + z@beta.T)\n",
    "\n",
    "# Scores\n",
    "s_0 = alpha + z[x == 0]@beta.T\n",
    "s_1 = alpha + z[x == 1]@beta.T\n",
    "\n",
    "# ROC curve and AUC\n",
    "fpr_class, tpr_class, _ = roc_curve(x, p_class)\n",
    "auc_class = auc(fpr_class, tpr_class)\n",
    "\n",
    "# Error\n",
    "error = np.mean((x-x_pred)**2)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_class = confusion_matrix(x, x_pred)\n",
    "cm_class = cm_class/np.sum(cm_class, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('arpm')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# Parameters\n",
    "orange = [0.94, 0.35, 0]\n",
    "green = [0, 0.5, 0]\n",
    "grtrue = [0, 0.4, 0]\n",
    "grhatch = [0, 0.1, 0]\n",
    "grfalse = [0.2, 0.6, 0]\n",
    "n_classes = 2\n",
    "plot_colors = \"rb\"\n",
    "plot_step = 0.02\n",
    "psi_zz1, psi_zz2 = np.meshgrid(np.arange(-2, 2, plot_step),\n",
    "                               np.arange(-2, 2, plot_step))\n",
    "idxx0 = np.where(np.abs(psi_z[:, 0]) <= 2)[0]\n",
    "idxx1 = np.where(np.abs(psi_z[:, 1]) <= 2)[0]\n",
    "idxx = np.intersect1d(idxx0, idxx1)\n",
    "\n",
    "# ROC curve\n",
    "ax1 = plt.subplot2grid((4, 4), (0, 0), colspan=2, rowspan=2)\n",
    "ax1.plot(fpr_class, tpr_class, color='b')\n",
    "ax1.set_xlabel('fpr')\n",
    "ax1.set_ylabel('tpr')\n",
    "ax1.text(0.6, 0., 'AUC = %.2f' % auc_class)\n",
    "plt.text(0.6, 0.2, 'Error = %.2f' % error)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.axis('square')\n",
    "ax1.set_title('ROC curve', fontweight='bold')\n",
    "\n",
    "# 3D plot\n",
    "ax2 = plt.subplot2grid((4, 4), (2, 0), colspan=2, rowspan=2, projection='3d')\n",
    "x_plot = chi_alphabeta(np.c_[psi_zz1.ravel(), psi_zz2.ravel()])\n",
    "x_plot = x_plot.reshape(psi_zz1.shape)\n",
    "ax2.plot_surface(psi_zz1, psi_zz2, x_plot,\n",
    "                 cmap=plt.cm.RdYlBu, alpha=0.7)\n",
    "\n",
    "# Scatter plot\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.intersect1d(np.where(x == i), idxx)\n",
    "    ax2.scatter3D(psi_z[idx, 0], psi_z[idx, 1], x[idx], c=color,\n",
    "                  label=['0', '1'][i],\n",
    "                  cmap=plt.cm.RdYlBu, s=10, alpha=1)\n",
    "ax2.view_init(30, -90)\n",
    "ax2.set_xlabel('$\\psi_1(Z)$')\n",
    "ax2.set_ylabel('$\\psi_2(Z)$')\n",
    "ax2.set_zlabel('$X$')\n",
    "ax2.set_title('Surface fitted with linear classifier', fontweight='bold')\n",
    "ax2.set_xlim([-2, 2])\n",
    "ax2.set_ylim([-2, 2])\n",
    "add_logo(fig, axis=ax2, location=2, size_frac_x=1/8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Regions plot\n",
    "ax3 = plt.subplot2grid((4, 4), (2, 2), colspan=2, rowspan=2)\n",
    "xx_pred = chi_alphabeta(np.c_[psi_zz1.ravel(), psi_zz2.ravel()])\n",
    "# Put the result into a color plot\n",
    "xx_pred = xx_pred.reshape(psi_zz1.shape)\n",
    "ax3.contourf(psi_zz1, psi_zz2, xx_pred, cmap=plt.cm.RdYlBu, alpha=0.5)\n",
    "# Scatter plot\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(x == i)\n",
    "    ax3.scatter(psi_z[idx, 0], psi_z[idx, 1], c=color,\n",
    "                label=['0', '1'][i],\n",
    "                cmap=plt.cm.RdYlBu, edgecolor='black', s=15, alpha=0.7)\n",
    "ax3.set_xlabel('$\\psi_1(Z)$')\n",
    "ax3.set_ylabel('$\\psi_2(Z)$')\n",
    "plt.xlim([-2, 2])\n",
    "plt.ylim([-2, 2])\n",
    "ax3.set_title('Decision regions', fontweight='bold')\n",
    "\n",
    "# Scores\n",
    "ax4 = plt.subplot2grid((4, 4), (0, 2), colspan=2, rowspan=1)\n",
    "ax4.hist(s_0, 80, density=True, alpha=0.7, color='r')\n",
    "ax4.hist(s_1, 80, density=True, alpha=0.7, color='b')\n",
    "yymax = ax4.get_ylim()[1]\n",
    "ax4.plot([0, 0], [0, yymax], 'k--')\n",
    "ax4.legend(['S | 0', 'S | 1'])\n",
    "ax4.set_title('Scores distribution', fontweight='bold')\n",
    "\n",
    "# Rates\n",
    "ax5 = plt.subplot2grid((4, 4), (1, 2), colspan=2, rowspan=1)\n",
    "ax5.fill([0.15, 0.15, 0.35, 0.35],\n",
    "         [0, cm_class[0, 1], cm_class[0, 1], 0], facecolor=grfalse,\n",
    "         edgecolor=grhatch, hatch='//', alpha=0.7)\n",
    "ax5.fill([0.15, 0.15, 0.35, 0.35],\n",
    "         [cm_class[0, 1], 1, 1, cm_class[0, 1]],\n",
    "         facecolor=grfalse, alpha=0.7)\n",
    "ax5.fill([0.45, 0.45, 0.65, 0.65],\n",
    "         [0, cm_class[1, 1], cm_class[1, 1], 0], facecolor=grtrue,\n",
    "         alpha=0.7)\n",
    "ax5.fill([0.45, 0.45, 0.65, 0.65],\n",
    "         [cm_class[1, 1], 1, 1, cm_class[1, 1]], facecolor=grtrue,\n",
    "         edgecolor=grhatch, hatch='\\\\\\\\', alpha=0.7)\n",
    "ax5.set_ylim([0, 1])\n",
    "ax5.legend(['fpr', 'tnr', 'tpr', 'fnr'], bbox_to_anchor=(0.001, -0.07, 1., .1),\n",
    "           facecolor='white',\n",
    "           loc=1, ncol=5, mode=\"expand\")\n",
    "ax5.set_title('Confusion matrix', fontweight='bold')\n",
    "ax5.set_xticks([])\n",
    "ax5.grid(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

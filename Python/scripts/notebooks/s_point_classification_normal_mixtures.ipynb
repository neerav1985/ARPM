{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_point_classification_normal_mixtures [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_point_classification_normal_mixtures&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=s_point_classification_normal_mixtures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.stats import norm\n",
    "\n",
    "from arpym.statistics.saddle_point_quadn import saddle_point_quadn\n",
    "from arpym.tools.plot_ellipse import plot_ellipse\n",
    "from arpym.tools.logo import add_logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_point_classification_normal_mixtures-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.4  # unconditional probability\n",
    "q = 0.7  # false positive error weight\n",
    "mu_z_0 = np.array([0, -1])  # expectation of Z given X=0\n",
    "sig2_z_0 = np.array([[49, -12], [-12, 36]])  # covariance of Z given X=0\n",
    "mu_z_1 = np.array([1, 5])  # expectation of Z given  X=1\n",
    "sig2_z_1 = np.array([[36, 11], [11, 49]])  # covariance of Z given X=1\n",
    "a = 0 # parameters of arbitrary linear score\n",
    "b = np.array([2, 0])\n",
    "j_ = 10**3  # number of scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_point_classification_normal_mixtures-implementation-step01): Compute conditional optimal score parameters, optimal scoring function and optimal predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of optimal scoring function\n",
    "alpha = np.log(p/(1-p)) -\\\n",
    "                0.5 * (np.log(np.linalg.det(np.linalg.solve(sig2_z_0, sig2_z_1))) +\n",
    "                mu_z_1 @ np.linalg.solve(sig2_z_1, mu_z_1) -\n",
    "                mu_z_0 @ np.linalg.solve(sig2_z_0, mu_z_0))\n",
    "beta = np.linalg.solve(sig2_z_1, mu_z_1) - np.linalg.solve(sig2_z_0, mu_z_0)\n",
    "gamma = -0.5 * (np.linalg.solve(sig2_z_1, np.identity(sig2_z_1.shape[0])) -\n",
    "                np.linalg.solve(sig2_z_0, np.identity(sig2_z_0.shape[0])))\n",
    "\n",
    "# optimal scoring function\n",
    "s_star = lambda z : alpha + beta @ z + z.T @ gamma @ z\n",
    "\n",
    "# optimal classifier\n",
    "lnq = np.log(q)\n",
    "ind_z = lambda z : s_star(z) > lnq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_point_classification_normal_mixtures-implementation-step02): Generate distribution of conditional optimal score, false positve rate and true positive rate of optimal scor, optimal ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf and pdf of conditional optimal score\n",
    "cdf_s_star_given_0 = lambda s_ : \\\n",
    "saddle_point_quadn(s_, alpha, beta.T, gamma, mu_z_0, sig2_z_0)[0]\n",
    "pdf_s_star_given_0 = lambda s_ : \\\n",
    "saddle_point_quadn(s_, alpha, beta.T, gamma, mu_z_0, sig2_z_0)[1]\n",
    "cdf_s_star_given_1 = lambda s_: \\\n",
    "saddle_point_quadn(s_, alpha, beta.T, gamma, mu_z_1, sig2_z_1)[0]\n",
    "pdf_s_star_given_1 = lambda s_: \\\n",
    "saddle_point_quadn(s_, alpha, beta.T, gamma, mu_z_1, sig2_z_1)[1]\n",
    "\n",
    "# false and true positive rate of optimal score\n",
    "fpr = lambda s_: 1 - cdf_s_star_given_0(s_)\n",
    "tpr = lambda s_: 1 - cdf_s_star_given_1(s_)\n",
    "\n",
    "# optimal false and true positive rate\n",
    "fpr_star = fpr(lnq)\n",
    "tpr_star = tpr(lnq)\n",
    "\n",
    "# optimal ROC curve\n",
    "roc = lambda s_: [fpr(s_), tpr(s_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_point_classification_normal_mixtures-implementation-step03): Generate distribution of conditional linear score, false positve rate and true positive rate of linear scor, ROC curve of linear score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf of conditional linear score\n",
    "cdf_s_given_0 = lambda s_: \\\n",
    "norm.cdf(s_, a +  b @ mu_z_0, np.sqrt(b @ sig2_z_0 @ b.T))\n",
    "cdf_s_given_1 = lambda s_: \\\n",
    "norm.cdf(s_, a +  b @ mu_z_1, np.sqrt(b @ sig2_z_1 @ b.T))\n",
    "\n",
    "# false positive rate and true positive rate of linear score\n",
    "fpr_lin = lambda s_: 1 - cdf_s_given_0(s_)\n",
    "tpr_lin = lambda s_: 1 - cdf_s_given_1(s_)\n",
    "\n",
    "# ROC curve of linear score\n",
    "roc_lin = lambda s_: [fpr_lin(s_), tpr_lin(s_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4](https://www.arpm.co/lab/redirect.php?permalink=s_point_classification_normal_mixtures-implementation-step04): Generate simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.binomial(1, p, j_)  # scenarios of output\n",
    "z_given_0 = np.random.multivariate_normal(mu_z_0, sig2_z_0, j_)\n",
    "z_given_1 = np.random.multivariate_normal(mu_z_1, sig2_z_1, j_)\n",
    "\n",
    "z = np.empty_like(z_given_0)\n",
    "x_bar = np.empty_like(x)\n",
    "for j in range(j_):\n",
    "    z[j]=(1-x[j])*z_given_0[j] + x[j]*z_given_1[j]  # scenarios of input  \n",
    "    x_bar[j]=ind_z((1-x[j])*z_given_0[j] + x[j]*z_given_1[j])  # classifier   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 5](https://www.arpm.co/lab/redirect.php?permalink=s_point_classification_normal_mixtures-implementation-step05): Expectation-covariance ellipsoid computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipse_muz0_sig2z0 = plot_ellipse(mu_z_0, sig2_z_0, r=2, display_ellipse=False)  # generate ellipsoid\n",
    "ellipse_muz1_sig2z1 = plot_ellipse(mu_z_1, sig2_z_1, r=2, display_ellipse=False)  # generate ellipsoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = [0, 0.5, 0]\n",
    "teal = [0.2344, 0.5820, 0.5664]\n",
    "light_teal = [0.2773, 0.7031, 0.6836]\n",
    "light_green_1 = [0.8398, 0.9141, 0.8125]\n",
    "light_green_2 = [0.6, 0.8008, 0.5039]\n",
    "grey = [0.5, 0.5, 0.5]\n",
    "colf = [0, 0.5412, 0.9020]\n",
    "darkgrey = [0.3, 0.3, 0.3]\n",
    "color_multiplier = 0.6\n",
    "x_colors = np.empty_like(x)\n",
    "x_colors[(x == 1) & (x_bar == 1)] = 1\n",
    "x_colors[(x == 1) & (x_bar == 0)] = 2\n",
    "x_colors[(x == 0) & (x_bar == 0)] = 3\n",
    "x_colors[(x == 0) & (x_bar == 1)] = 4\n",
    "\n",
    "# grid for optimal roc curve\n",
    "s_min = -20\n",
    "s_max = 20\n",
    "s_star_grid = np.arange(s_min, s_max, 0.05)\n",
    "s_star_grid_index = np.argmin(abs(lnq-s_star_grid))\n",
    "\n",
    "# grid for linear roc curve\n",
    "s_lin_grid = np.linspace(-500, 500, 1000)\n",
    "\n",
    "plt.style.use('arpm')\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = plt.subplot2grid((3, 2), (0, 0), rowspan=2, colspan=1)\n",
    "divider = make_axes_locatable(ax1)\n",
    "\n",
    "# dummy legend plots\n",
    "ax1.fill_between([5, 5], [5, 5], [5, 5], facecolor=light_green_1, label='fnr')\n",
    "ax1.fill_between([5, 5], [5, 5], [5, 5], facecolor=light_green_2, label='tpr')\n",
    "ax1.fill_between([5, 5], [5, 5], [5, 5], facecolor=teal, label='tnr')\n",
    "ax1.fill_between([5, 5], [5, 5], [5, 5], facecolor=light_teal, label='fpr')\n",
    "\n",
    "# Optimal ROC curve and classifier, arbitrary ROC curve, Neyman-Pearson region\n",
    "fpr_grid=fpr(s_star_grid)\n",
    "tpr_grid=tpr(s_star_grid)\n",
    "\n",
    "fpr_lin_grid=fpr_lin(s_lin_grid)\n",
    "tpr_lin_grid=tpr_lin(s_lin_grid)\n",
    "\n",
    "ax1.plot(fpr_grid, tpr_grid, color=green, lw=0.75, label='Best ROC')\n",
    "ax1.plot(fpr_star, tpr_star,\n",
    "         'ro', markersize=8, label='Optimal classifier')\n",
    "ax1.plot(fpr_lin_grid, tpr_lin_grid, 'k--', linewidth=0.75, label='Arbitrary ROC')\n",
    "ax1.fill(1-fpr_grid, 1-tpr_grid, color='grey', alpha=0.3)\n",
    "ax1.fill(fpr_grid, tpr_grid, color='grey', alpha=0.3)\n",
    "\n",
    "# non-predictive classifier\n",
    "ax1.plot([0, 1], [0, 1], 'k', lw=0.75, label='Non-predictive classifier')\n",
    "ax1.axis('square')\n",
    "ax1.set_xlim([0, 1])\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel('FPR (and TNR)', labelpad=18)\n",
    "ax1.set_ylabel('TPR (and FNR)', labelpad=22)\n",
    "ax1.legend(facecolor='none', edgecolor='none', loc=4, ncol=2)\n",
    "ax1.set_title('ROC curve')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "# TPR\n",
    "ax2 = divider.append_axes('left', size='3%', pad=0)\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.fill_between([0, 1], [1, 1], 0, facecolor=light_green_1)\n",
    "ax2.fill_between([0, 1], [tpr_star, tpr_star], 0, facecolor=light_green_2)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks(np.arange(0, 1, 0.2))\n",
    "ax2.tick_params(axis='both', which='major', pad=0)\n",
    "\n",
    "# FPR\n",
    "ax3 = divider.append_axes('bottom', size='3%', pad=0)\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.fill_between([0, 1], [1, 1], 0, facecolor=teal)\n",
    "ax3.fill_between([0, fpr_star], [1, 1], 0,\n",
    "                 facecolor=light_teal)\n",
    "ax3.set_xticks(np.arange(0, 1, 0.2))\n",
    "ax3.set_yticks([])\n",
    "ax3.tick_params(axis='both', which='major', pad=0)\n",
    "\n",
    "ax4 = plt.subplot2grid((6, 2), (4, 0), rowspan=1, colspan=1)\n",
    "\n",
    "# Optimal score distribution S|0\n",
    "pdf_s_star_given_0_grid=pdf_s_star_given_0(s_star_grid)\n",
    "ax4.fill_between(s_star_grid[s_star_grid_index:],\n",
    "                 pdf_s_star_given_0_grid[s_star_grid_index:],\n",
    "                 0, facecolor=light_teal)\n",
    "ax4.fill_between(s_star_grid[:s_star_grid_index],\n",
    "                 pdf_s_star_given_0_grid[:s_star_grid_index:],\n",
    "                 0, facecolor=teal)\n",
    "ax4.plot(s_star_grid, pdf_s_star_given_0_grid, c=[x*color_multiplier for x in light_green_2], lw=2)\n",
    "ax4.annotate(r'Optimal score $S^*|0$', (0.06, 0.31),\n",
    "             xycoords='figure fraction', size=14.5)\n",
    "ylimm = ax4.get_ylim()\n",
    "ax4.plot([lnq, lnq], ylimm, c=colf, lw=1.5)\n",
    "ax4.text(lnq, 0.8*ylimm[1], r'$\\ln q$')\n",
    "ax4.set_xticks([])\n",
    "ax4.set_xlim([s_min, s_max])\n",
    "ax4.grid(False)\n",
    "\n",
    "ax5 = plt.subplot2grid((6, 2), (5, 0), rowspan=1, colspan=1)\n",
    "\n",
    "# Optimal score distribution S|1\n",
    "pdf_s_star_given_1_grid=pdf_s_star_given_1(s_star_grid)\n",
    "ax5.fill_between(s_star_grid[s_star_grid_index:],\n",
    "                 pdf_s_star_given_1_grid[s_star_grid_index:],\n",
    "                 0, facecolor=light_green_2)\n",
    "ax5.fill_between(s_star_grid[:s_star_grid_index],\n",
    "                 pdf_s_star_given_1_grid[:s_star_grid_index:],\n",
    "                 0, facecolor=light_green_1)\n",
    "ax5.plot(s_star_grid, pdf_s_star_given_1_grid, c=[x*color_multiplier for x in light_green_2], lw=2)\n",
    "ax5.plot([lnq, lnq], ylimm, c=colf, lw=1.5)\n",
    "ax5.set_xlim([s_min, s_max])\n",
    "ax5.annotate(r'Optimal score $S^*|1$', (0.06, 0.16),\n",
    "             xycoords='figure fraction', size=14.5)\n",
    "ax5.grid(False)\n",
    "\n",
    "ax6 = plt.subplot2grid((2, 2), (0, 1), rowspan=1, colspan=1, projection='3d')\n",
    "\n",
    "# Optimal score\n",
    "zlim = [-40, 40]\n",
    "z_grid = np.arange(zlim[0], zlim[1], 0.5)\n",
    "i_ = z_grid.size\n",
    "s_star_meshgrid=np.empty([i_, i_])\n",
    "for i in range(i_):\n",
    "    for j in range(i_):\n",
    "        s_star_meshgrid[i,j]=s_star(np.array([z_grid[i],z_grid[j]]))\n",
    "        \n",
    "z_region_meshgrid=s_star_meshgrid > lnq\n",
    "z_column, z_row = np.meshgrid(z_grid, z_grid)        \n",
    "\n",
    "ax6.plot3D(z_column[z_region_meshgrid],\n",
    "           z_row[z_region_meshgrid],\n",
    "           lnq*np.ones_like(s_star_meshgrid[z_region_meshgrid]),\n",
    "           's', ms=4, c=colf, alpha=0.15)\n",
    "ax6.contour(z_column, z_row, s_star_meshgrid, levels=np.arange(-100, 100, 5),\n",
    "            colors=[[x*color_multiplier for x in light_green_2]],\n",
    "            linewidths=2, linestyles=['solid'])\n",
    "ax6.set_xlim(zlim)\n",
    "ax6.set_ylim(zlim)\n",
    "ax6.set_zlim([-100, 100])\n",
    "ax6.set_xlabel(r'$z_{1}$')\n",
    "ax6.set_ylabel(r'$z_2$')\n",
    "ax6.set_zlabel(r'$s$')\n",
    "ax6.set_title(r'Optimal score $s^*(z)$')\n",
    "\n",
    "ax7 = plt.subplot2grid((2, 2), (1, 1), rowspan=1, colspan=1, projection='3d')\n",
    "\n",
    "# Optimal predictor\n",
    "ax7.plot3D(z_column[z_region_meshgrid],\n",
    "           z_row[z_region_meshgrid],\n",
    "           np.ones_like(z_column[z_region_meshgrid]),\n",
    "           's', ms=4, c=[0.8, 0.8, 0.8], alpha=0.3)\n",
    "ax7.plot3D(z_column[~z_region_meshgrid],\n",
    "           z_row[~z_region_meshgrid],\n",
    "           np.zeros_like(z_column[~z_region_meshgrid]),\n",
    "           's', ms=4, c=[0.8, 0.8, 0.8], alpha=0.3)\n",
    "ax7.plot(z[:, 0][x_colors == 1], z[:, 1][x_colors == 1], x[x_colors == 1],\n",
    "         'o', ms=3, c=light_green_2)\n",
    "ax7.plot(z[:, 0][x_colors == 2], z[:, 1][x_colors == 2], x[x_colors == 2],\n",
    "         'o', ms=3, c=light_green_1)\n",
    "ax7.plot(z[:, 0][x_colors == 3], z[:, 1][x_colors == 3], x[x_colors == 3],\n",
    "         'o', ms=3, c=teal)\n",
    "ax7.plot(z[:, 0][x_colors == 4], z[:, 1][x_colors == 4], x[x_colors == 4],\n",
    "         'o', ms=3, c=light_teal)\n",
    "\n",
    "# mean/covariance ellipses\n",
    "ax7.plot(ellipse_muz0_sig2z0[:, 0], ellipse_muz0_sig2z0[:, 1], np.zeros_like(ellipse_muz0_sig2z0[:, 0]), c='k', lw=.5)\n",
    "ax7.plot(ellipse_muz1_sig2z1[:, 0], ellipse_muz1_sig2z1[:, 1], np.ones_like(ellipse_muz1_sig2z1[:, 0]), c='k', lw=0.5)\n",
    "ax7.plot([mu_z_0[0]], [mu_z_0[1]], [0], 'o', ms=3, c='k')\n",
    "ax7.plot([mu_z_1[0]], [mu_z_1[1]], [1], 'o', ms=3, c='k')\n",
    "ax7.set_xlim(zlim)\n",
    "ax7.set_ylim(zlim)\n",
    "ax7.set_zlim([0, 1.2])\n",
    "ax7.set_zticks([0, 1])\n",
    "ax7.set_xlabel(r'$z_{1}$')\n",
    "ax7.set_ylabel(r'$z_2$')\n",
    "ax7.set_zlabel(r'$x$')\n",
    "ax7.set_title(r'Optimal predictor $\\bar{x}=1_{s^*(z)>\\bar{s}^*}$')\n",
    "\n",
    "add_logo(fig, size_frac_x=1/9)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

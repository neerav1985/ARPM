{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_fit_garch_stocks [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_fit_garch_stocks&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=s_fit_garch_stocks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from arpym.estimation.conditional_fp import conditional_fp\n",
    "from arpym.estimation.exp_decay_fp import exp_decay_fp\n",
    "from arpym.estimation.fit_garch_fp import fit_garch_fp\n",
    "from arpym.statistics.meancov_sp import meancov_sp\n",
    "from arpym.statistics.scoring import scoring\n",
    "from arpym.statistics.smoothing import smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_fit_garch_stocks-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_hl_garch = 3*252  # half life for GARCH fit\n",
    "tau_hl_pri = 3*252  # half life for VIX comp. ret. time conditioning\n",
    "tau_hl_smooth = 4*21  # half life for VIX comp. ret. smoothing\n",
    "tau_hl_score = 5*21  # half life for VIX comp. ret. scoring\n",
    "alpha_leeway = 1/4  # probability included in the range centered in z_vix_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 0](https://www.arpm.co/lab/redirect.php?permalink=s_fit_garch_stocks-implementation-step00): Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_glob = '~/databases/global-databases/'\n",
    "\n",
    "# Stocks\n",
    "db_stocks_sp = pd.read_csv(path_glob +\n",
    "                           'equities/db_stocks_SP500/db_stocks_sp.csv',\n",
    "                           header=1, index_col=0, parse_dates=True)\n",
    "stocks_names = db_stocks_sp.columns.tolist()\n",
    "\n",
    "\n",
    "# VIX (used for time-state conditioning)\n",
    "vix_path = path_glob + 'derivatives/db_vix/data.csv'\n",
    "db_vix = pd.read_csv(vix_path, usecols=['date', 'VIX_close'],\n",
    "                     index_col=0, parse_dates=True)\n",
    "\n",
    "# intersect dates\n",
    "dates_rd = pd.DatetimeIndex.intersection(db_stocks_sp.index, db_vix.index)\n",
    "\n",
    "# update databases\n",
    "db_stocks_sp = db_stocks_sp.loc[dates_rd, :]\n",
    "db_vix = db_vix.loc[dates_rd, :]\n",
    "\n",
    "dates = dates_rd[1:]\n",
    "t_ = len(dates)\n",
    "\n",
    "# values\n",
    "v = db_stocks_sp.values\n",
    "vix = db_vix.values[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_fit_garch_stocks-implementation-step01): Risk drivers identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.log(v)  # log-values\n",
    "d_ = x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_fit_garch_stocks-implementation-step02): Quest for invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ = d_\n",
    "epsi = np.zeros((t_, i_))\n",
    "p_garch = exp_decay_fp(t_, tau_hl_garch)\n",
    "\n",
    "for i in range(i_):\n",
    "    print('Fitting ' + str(i+1) + '-th GARCH; ' +\n",
    "          str(int((i+1)/i_*100)) + '% done.')\n",
    "    _, _, epsi[:, i] = fit_garch_fp(np.diff(x[:, i], axis=0), p_garch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_fit_garch_stocks-implementation-step03): Historical estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time and state conditioning on smoothed and scored VIX returns\n",
    "\n",
    "# state indicator: VIX compounded return realizations\n",
    "c_vix = np.diff(np.log(vix))\n",
    "# smoothing\n",
    "z_vix = smoothing(c_vix, tau_hl_smooth)\n",
    "# scoring\n",
    "z_vix = scoring(z_vix, tau_hl_score)\n",
    "# target value\n",
    "z_vix_star = z_vix[-1]\n",
    "# flexible probabilities\n",
    "p_pri = exp_decay_fp(len(dates), tau_hl_pri)\n",
    "p = conditional_fp(z_vix, z_vix_star, alpha_leeway, p_pri)\n",
    "\n",
    "mu_hat, sig2_hat = meancov_sp(epsi, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({stocks_names[i]: epsi[:, i]\n",
    "                    for i in range(i_)}, index=dates)\n",
    "out = out[list(stocks_names[:i_])]\n",
    "out.index.name = 'dates'\n",
    "out.to_csv('~/databases/temporary-databases/db_fit_garch_stocks_epsi.csv')\n",
    "\n",
    "out = pd.DataFrame({'mu_hat': pd.Series(mu_hat.reshape(-1)),\n",
    "                    'sig2_hat': pd.Series(sig2_hat.reshape(-1))})\n",
    "out.to_csv(\n",
    "          '~/databases/temporary-databases/db_fit_garch_stocks_locdisp.csv',\n",
    "          index=None)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

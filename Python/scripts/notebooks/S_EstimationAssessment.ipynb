{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_EstimationAssessment [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_EstimationAssessment&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=ExEstimAssess)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange, ones, zeros, sort, argsort, cumsum, percentile, diag, eye, round, mean, log, exp, tile, \\\n",
    "    histogram, array, r_, corrcoef, real, diagflat\n",
    "from numpy import sum as npsum, max as npmax\n",
    "from numpy.linalg import eig, norm as linalgnorm\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, plot, bar, xlim, ylim, yticks\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from ARPM_utils import save_plot, struct_to_dict, matlab_percentile\n",
    "from intersect_matlab import intersect\n",
    "from MinRelEntFP import MinRelEntFP\n",
    "from NormalScenarios import NormalScenarios\n",
    "from EffectiveScenarios import EffectiveScenarios\n",
    "from ConditionalFP import ConditionalFP\n",
    "from FactorAnalysis import FactorAnalysis\n",
    "from CopMargComb import CopMargComb\n",
    "\n",
    "# initialize variables\n",
    "i_ = 25  # number of stocks\n",
    "t_ = 100  # len of time series\n",
    "j_ = 500  # number of simulated time series for each k-th DGP [low for speed increase for accuracy]\n",
    "k_ = 5  # number of perturbed DGP's [low for speed]\n",
    "h = 0  # DGP whose loss is plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_StocksS_P'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_StocksS_P'), squeeze_me=True)\n",
    "\n",
    "Data = struct_to_dict(db['Data'])\n",
    "\n",
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_VIX'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_VIX'), squeeze_me=True)\n",
    "\n",
    "VIX = struct_to_dict(db['VIX'], as_namedtuple=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the stocks' log-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_x = Data.Dates\n",
    "x = Data.Prices\n",
    "\n",
    "# compute the log-returns\n",
    "epsi = log(x[:i_, 1:]/ x[:i_, : -1])\n",
    "# conditioning variable (VIX)\n",
    "z = VIX['value']\n",
    "dates_z = VIX['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the datasets and select the first t_end observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[dates, i_x, i_z] = intersect(dates_x, dates_z)\n",
    "\n",
    "epsi = epsi[:, i_x[:t_]]\n",
    "z = z[i_z[:t_]].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the distribution of the invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "d = zeros((1, i_))\n",
    "rank = 1  # rank\n",
    "\n",
    "c2 = np.corrcoef(epsi)\n",
    "c2, *_ = FactorAnalysis(c2, d, rank)\n",
    "c2 = real(c2)\n",
    "\n",
    "# Marginals\n",
    "# prior\n",
    "lam = 0.0005\n",
    "prior = exp(lam*(arange(1,t_+1))).reshape(1,-1)\n",
    "prior = prior / npsum(prior)\n",
    "\n",
    "# conditioner\n",
    "VIX = namedtuple('VIX', 'Series TargetValue Leeway')\n",
    "VIX.Series = z\n",
    "VIX.TargetValue = np.atleast_2d(matlab_percentile(z.flatten(), 100 * 0.7))\n",
    "VIX.Leeway = 0.35\n",
    "\n",
    "# flexible probabilities conditioned via EP\n",
    "p = ConditionalFP(VIX, prior)\n",
    "\n",
    "# effective number of scenarios\n",
    "typ = namedtuple('type','Entropy')\n",
    "typ.Entropy = 'Exp'\n",
    "ens = EffectiveScenarios(p, typ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform estimation assessment: compute errors for each perturbed DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise\n",
    "Z = norm.rvs(0, 1, size=[i_, k_])\n",
    "# compute base case eigenvalues\n",
    "DiagLambda2, e = eig(c2)\n",
    "log_lambda2_base = log(DiagLambda2)\n",
    "# initialize\n",
    "c2_DGP = {}\n",
    "p_DGP = {}\n",
    "y = zeros((i_, t_))\n",
    "ff = zeros((i_, t_))\n",
    "C2_hat = zeros((i_, i_, j_))\n",
    "C2_bar = zeros((i_, i_, j_))\n",
    "L_hat = zeros(j_)\n",
    "L_bar = zeros(j_)\n",
    "er_hat = zeros(k_)\n",
    "er_bar = zeros(k_)\n",
    "\n",
    "for k in trange(k_,desc='DGP'):\n",
    "    # Perturb DGP\n",
    "    if k == 0:\n",
    "        c2_DGP[k] = real(c2)\n",
    "        p_DGP[k] = tile(p, (i_, 1))\n",
    "    else:\n",
    "        # perturb correlation matrix\n",
    "        log_lambda2 = log_lambda2_base + Z[:, k] / 100\n",
    "        lambda2 = exp(log_lambda2)\n",
    "        c2_DGP[k] = e@diagflat(lambda2)@e.T\n",
    "        c2_DGP[k][eye(i_) == 1] = 1\n",
    "        # perturb marginals\n",
    "        p_DGP[k] = zeros((i_,t_))\n",
    "        for i in range(i_):\n",
    "            a =r_[ones((1, t_)), epsi[[i],:]]\n",
    "            b = r_[array([[1]]),(p@epsi[[i], :].T)*Z[i, k] / 100]\n",
    "            p_DGP[k][i, :] = MinRelEntFP(p, None, None, a, b)[0]\n",
    "\n",
    "    # marginals for CMA-combination\n",
    "    for i in range(i_):\n",
    "        y[i, :], idy = sort(epsi[i,:]), argsort(epsi[i,:])\n",
    "        # f = p_DGP[k][0,idy]\n",
    "        f = p_DGP[k][i,idy]\n",
    "        ff[i, :] = cumsum(f)\n",
    "\n",
    "    for j in range(j_):\n",
    "        # Randomize time series I\n",
    "        m, _ = NormalScenarios(zeros((i_, 1)), c2_DGP[k], t_, 'Riccati')\n",
    "        U1 = norm.cdf(m)\n",
    "        if npsum(U1==0) >= 1:\n",
    "            print(k)\n",
    "        I = CopMargComb(y, ff, U1)\n",
    "\n",
    "        # Evaluate the correlation estimators\n",
    "        C2_hat[:,:, j] = corrcoef(I)  # sample correlation\n",
    "        C2_bar[:,:, j] = real(FactorAnalysis(C2_hat[:,:, j], d, rank)[0])  # shrinkage correlation\n",
    "\n",
    "        # Compute the losses\n",
    "        L_hat[j] = linalgnorm(C2_hat[:,:, j]-c2_DGP[k], ord='fro')**2  # sample loss\n",
    "        L_bar[j] = linalgnorm(C2_bar[:,:, j]-c2_DGP[k], ord='fro')**2  # shrinkage loss\n",
    "\n",
    "    # Compute errors\n",
    "    er_hat[k] = mean(L_hat)  # sample error\n",
    "    er_bar[k] = mean(L_bar)  # shrinkage error\n",
    "\n",
    "    # store loss's distribution and bias for the selected h-th DGP\n",
    "    if k == h:\n",
    "        # histograms\n",
    "        nbins = int(round(10*log(j_)))\n",
    "        hgram_hat, x_hat = histogram(L_hat, nbins)\n",
    "        hgram_hat = hgram_hat / (nbins*(x_hat[1] - x_hat[0]))\n",
    "        hgram_bar, x_bar = histogram(L_bar, nbins)\n",
    "        hgram_bar = hgram_bar / (nbins*(x_bar[1] - x_bar[0]))\n",
    "\n",
    "        # compute bias\n",
    "        bias_hat = linalgnorm(mean(C2_hat, 2) - c2_DGP[k], ord='fro')\n",
    "        bias_bar = linalgnorm(mean(C2_bar, 2) - c2_DGP[k], ord='fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute robust and ensemble errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust\n",
    "er_rob_hat = npmax(er_hat)\n",
    "er_rob_bar = npmax(er_bar)\n",
    "\n",
    "# Ensemble with equal weigths\n",
    "er_ens_hat = mean(er_hat)\n",
    "er_ens_bar = mean(er_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colhist = [.8, .8, .8]\n",
    "orange = [1, 0.4, 0]\n",
    "dark = [0.2, 0.2, 0.2]\n",
    "blue = [0, 0.4, 1]\n",
    "\n",
    "M = max(npmax(x_hat), npmax(x_bar))\n",
    "\n",
    "f, ax = plt.subplots(1, 2)\n",
    "plt.sca(ax[0])\n",
    "plt.axis()\n",
    "# sample correlation\n",
    "LOSS = bar(x_hat[:-1], hgram_hat,width=x_hat[1]-x_hat[0], facecolor=colhist,edgecolor= colhist,zorder=0)\n",
    "xlim([0, 1.1*M])\n",
    "ylim([0, 1.1*npmax(hgram_hat)])\n",
    "yticks([])  #\n",
    "plot([0, bias_hat ** 2], [npmax(hgram_hat)*0.01, npmax(hgram_hat)*0.01], color=orange, lw=5,zorder=2)\n",
    "plot([bias_hat ** 2, er_hat[k]], [npmax(hgram_hat)*0.01, npmax(hgram_hat)*0.01], color=blue, lw=5,zorder=1)\n",
    "plot([0, er_hat[k]], [npmax(hgram_hat)*0.04, npmax(hgram_hat)*0.04], color=dark, lw=5,zorder=1)\n",
    "plot([0, 0], [0, 0], color='lightgreen',marker='o',markerfacecolor='g',zorder=3)\n",
    "# global title\n",
    "f.suptitle('LOSS DISTRIBUTIONS')\n",
    "# title\n",
    "ax[0].set_title('Sample correlation')\n",
    "S_B = 'Bias$^2$:  % 3.2f'% (bias_hat**2)\n",
    "plt.text(0.01*M, -0.15*npmax(hgram_hat), S_B, color=orange,horizontalalignment='left')\n",
    "S_I = 'Ineff$^2$ :  % 3.2f'%(er_hat[k]-bias_hat**2)\n",
    "plt.text(0.01*M, -0.25*npmax(hgram_hat), S_I, color='b',horizontalalignment='left')\n",
    "S_E = 'Error:  % 3.2f'%er_hat[k]\n",
    "plt.text(0.01*M, -0.35*npmax(hgram_hat), S_E, color=dark,horizontalalignment='left')\n",
    "S_WCE = 'Robust Error:  % 3.2f'%er_rob_hat\n",
    "plt.text(M, -0.25*npmax(hgram_hat), S_WCE, color='r',horizontalalignment='right')\n",
    "S_EH = 'Ensemble Error:  % 3.2f'%er_ens_hat\n",
    "plt.text(M, -0.35*npmax(hgram_hat), S_EH, color='r',horizontalalignment='right')\n",
    "num = 'Test Data Generating Process:  % 3.0f of %3.0f'%(h+1,k_)\n",
    "plt.text(0, 1.23*npmax(hgram_hat), num, color='k',horizontalalignment='left')\n",
    "# shrinkage\n",
    "plt.sca(ax[1])\n",
    "bar(x_bar[:-1], hgram_bar, width=x_bar[1]-x_bar[0], facecolor=colhist,edgecolor= colhist,zorder=0)\n",
    "xlim([0, 1.1*M])\n",
    "ylim([0, 1.1*npmax(hgram_bar)])\n",
    "plt.yticks([])\n",
    "plot([0, bias_bar**2], [npmax(hgram_bar)*0.01, npmax(hgram_bar)*0.01], color=orange, lw=5,zorder=2)\n",
    "plot([bias_bar**2, er_bar[k]], [npmax(hgram_bar)*0.01, npmax(hgram_bar)*0.01], color=blue, lw=5,zorder=1)\n",
    "plot([0, er_bar[k]], [npmax(hgram_bar)*0.04, npmax(hgram_bar)*0.04], color=dark, lw=5,zorder=1)\n",
    "plot([0,0], [0,0], color='lightgreen',marker='o',markerfacecolor='g',zorder=3)\n",
    "# title\n",
    "ax[1].set_title('Shrinkage correlation')\n",
    "B = 'Bias$^2$  % 3.2f'% bias_bar**2\n",
    "plt.text(0.01*M, -0.15*npmax(hgram_bar), B, color=orange,horizontalalignment='left')\n",
    "I = 'Ineff$^2$: % 3.2f'%(er_bar[k]-bias_bar**2)\n",
    "plt.text(0.01*M, -0.25*npmax(hgram_bar), I, color='b',horizontalalignment='left')\n",
    "E = 'Error:  % 3.2f'%er_bar[k]\n",
    "plt.text(0.01*M, -0.35*npmax(hgram_bar), E, color=dark,horizontalalignment='left')\n",
    "WCE = 'Robust Error:  % 3.2f'%er_rob_bar\n",
    "plt.text(M, -0.25*npmax(hgram_bar), WCE, color='r',horizontalalignment='right')\n",
    "EH = 'Ensemble Error:  % 3.2f'%er_ens_bar\n",
    "plt.text(M, -0.35*npmax(hgram_bar), EH, color='r',horizontalalignment='right')\n",
    "f.subplots_adjust(bottom=0.3,top=0.85);\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

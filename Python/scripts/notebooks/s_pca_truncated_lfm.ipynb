{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_pca_truncated_lfm [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_pca_truncated_lfm&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-trunc-statistical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import rc, rcParams\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "rc('text', usetex=True)\n",
    "rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath} \\usepackage{amssymb}\"]\n",
    "\n",
    "from arpym.statistics.meancov_sp import meancov_sp\n",
    "from arpym.estimation.cov_2_corr import cov_2_corr\n",
    "from arpym.tools.histogram_sp import histogram_sp\n",
    "from arpym.tools.pca_cov import pca_cov\n",
    "from arpym.tools.logo import add_logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = 10  # number of factors\n",
    "n_plus = 10  # long position index\n",
    "n_minus = 200  # short position index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 0](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step00): Load the weekly time series of the stock values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/databases/global-databases/equities/db_stocks_SP500/'\n",
    "data = pd.read_csv(path + 'db_stocks_sp.csv', index_col=0, header=[0, 1],\n",
    "                   parse_dates=True)\n",
    "n_ = len(data.columns)-1\n",
    "v = data.iloc[:, 1:n_+1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step01): Compute linear returns of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = v[1:, :] / v[:-1, :] - 1  # linear returns\n",
    "t_ = x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step02): Estimate expectation and covariance of X and define sigma matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_x_hat, s2_x_hat = meancov_sp(x)  # HFP moments\n",
    "sigma2 = np.diag(np.diag(s2_x_hat))  # scale matrix\n",
    "sigma = np.sqrt(sigma2)\n",
    "sigma_inv = np.diag(1/np.diag(sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step03): Compute principal component decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_hat, lambda2_hat = pca_cov(sigma_inv@s2_x_hat@sigma_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step04): Estimate the loadings, the factor extraction matrix and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_hat_pc = m_x_hat  # shift\n",
    "beta_hat_pc = sigma@e_hat[:, :k_]  # loadings\n",
    "gamma_hat_pc = e_hat[:, :k_].T@sigma_inv  # construction matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 5](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step05): Compute the factor realizations and their expectation and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat_pc = (x - m_x_hat)@gamma_hat_pc.T  # factors\n",
    "m_z_hat, s2_z_hat = meancov_sp(z_hat_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 6](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step06): Compute the residuals and the joint sample covariance of residuals and factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = x - (alpha_hat_pc + z_hat_pc@beta_hat_pc.T)  # residuals\n",
    "_, s2_uz_hat = meancov_sp((np.c_[u, z_hat_pc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 7](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step07): Compute correlations among  residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_uz_hat, _ = cov_2_corr(s2_uz_hat)\n",
    "c2_u_hat = c2_uz_hat[:n_, :n_]  # correlation among residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 8](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step08): Compute the truncated covariance of the returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_u_hat = s2_uz_hat[:n_, :n_]\n",
    "s_u_hat = np.sqrt(np.diag(s2_u_hat))\n",
    "s2_x_trunc = beta_hat_pc@s2_z_hat@beta_hat_pc.T +\\\n",
    "                    np.diag(np.diag(s_u_hat))  # truncated covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 9](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step09): Estimate the standard deviations of the portfolio returns using the sample covariance and the truncated covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 1 / n_*np.ones((n_, 1))  # equal-weights portfolio\n",
    "\n",
    "w2 = np.zeros((n_, 1))  # long-short portfolio\n",
    "w2[n_plus] = 2\n",
    "w2[n_minus] = -1\n",
    "\n",
    "# HFP std of equal-weights portfolio\n",
    "s_1_hat = np.sqrt(w1.T@s2_x_hat@w1)\n",
    "# truncated std of equal-weights portfolio\n",
    "s_1_trunc = np.sqrt(w1.T@s2_x_trunc@w1)\n",
    "\n",
    "# HFP std of long-short portfolio\n",
    "s_2_hat = np.sqrt(w2.T@s2_x_hat@w2)\n",
    "# truncated std of long-short portfolio\n",
    "s_2_trunc = np.sqrt(w2.T@s2_x_trunc@w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 10](https://www.arpm.co/lab/redirect.php?permalink=s_pca_truncated_lfm-implementation-step10): Define data used for ploting of the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f_l, xi_l] = histogram_sp(c2_u_hat[np.triu_indices(c2_u_hat.shape[0],\n",
    "                           1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Figure specifications\n",
    "plt.style.use('arpm')\n",
    "\n",
    "# Histogram: correlations among residuals\n",
    "\n",
    "mydpi = 72.0\n",
    "fig = plt.figure(figsize=(1280.0/mydpi,720.0/mydpi),dpi=mydpi)\n",
    "ax0 = plt.axes([0.595, 0.83, 0.92, 0.45])\n",
    "ax0.plot(c2_u_hat.mean(),0,'ro')\n",
    "plt.xlim(-0.6, 1.6)\n",
    "plt.ylim(0, 9)\n",
    "h = plt.bar(xi_l, f_l, width=xi_l[1]-xi_l[0],\n",
    "            facecolor=[.7, .7, .7],\n",
    "            edgecolor='k')\n",
    "plt.text(0.3, 6.5, r'$\\mathbb{C}$' + r'$r$' + r'$\\{U_m, U_n\\}$',\n",
    "         fontsize=20)\n",
    "plt.xlabel(r'Correlation values', fontsize=17)\n",
    "plt.ylabel(r'Frequencies', fontsize=17)\n",
    "ax0.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "c2_x, _ = cov_2_corr(s2_x_hat)\n",
    "c2_x = np.tril(c2_x[:n_, :n_], -1)\n",
    "corr_x = c2_x[np.nonzero(c2_x)]  # reshape the correlations\n",
    "n, xout = histogram_sp(corr_x)\n",
    "\n",
    "ax1 = plt.axes([0.595, 0.3, 0.92, 0.45])\n",
    "plt.xlim(-0.6, 1.6)\n",
    "plt.ylim(0, 4)\n",
    "ax1.plot(corr_x.mean(),0,'ro')\n",
    "ax1.axes.get_xaxis().set_ticks([])\n",
    "h1 = ax1.bar(xout, n, width=xout[1]-xout[0], facecolor=[.7, .7, .7], edgecolor='k')\n",
    "plt.ylabel(r'Frequencies', fontsize=17)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.text(0.6, 3.8, r'$\\mathbb{C}$' + r'$r$' + r'$\\{X_{m,t}, X_{n,t}\\}$',\n",
    "         fontsize=20)\n",
    "ax1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "add_logo(fig, location=4)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

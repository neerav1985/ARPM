{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_reg_truncated_lfm [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_reg_truncated_lfm&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-trunc-time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from arpym.statistics.meancov_sp import meancov_sp\n",
    "from arpym.estimation.fit_lfm_ols import fit_lfm_ols\n",
    "from arpym.estimation.cov_2_corr import cov_2_corr\n",
    "from arpym.tools.histogram_sp import histogram_sp\n",
    "from arpym.tools.logo import add_logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_reg_truncated_lfm-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot = np.array([0, 1, 9])  # targets and factors to spot\n",
    "n_long = 61  # long index\n",
    "n_short = np.array([366, 244])  # short indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 0](https://www.arpm.co/lab/redirect.php?permalink=s_reg_truncated_lfm-implementation-step00): Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/databases/global-databases/equities/db_stocks_SP500/'\n",
    "data = pd.read_csv(path + 'db_stocks_sp.csv', index_col=0, header=[0, 1],\n",
    "                   parse_dates=True)\n",
    "idx_sector = pd.read_csv(path + 'db_sector_idx.csv', index_col=0,\n",
    "                         parse_dates=True)\n",
    "idx_sector = idx_sector.drop(\"RealEstate\", axis=1)  # delete RealEstate\n",
    "\n",
    "dates = np.intersect1d(data.index, idx_sector.index)\n",
    "data = data.loc[dates]\n",
    "idx_sector = idx_sector.loc[dates]\n",
    "\n",
    "t_ = len(data.index) - 1\n",
    "n_ = len(data.columns)\n",
    "k_ = len(idx_sector.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_reg_truncated_lfm-implementation-step01): Compute linear returns of X and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_stock = data.values  # stock values\n",
    "x = (v_stock[1:, :] - v_stock[:-1, :]) / v_stock[:-1, :]  # linear return of the stock values\n",
    "v_sector = idx_sector.values  # sector indices\n",
    "z = (v_sector[1:, :] - v_sector[:-1, :]) / v_sector[:-1, :]  # linear return of the sector indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_reg_truncated_lfm-implementation-step02): Compute OLSFP estimates and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta, s2, eps = fit_lfm_ols(x, z) #  compute OLSFP estimates and residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_reg_truncated_lfm-implementation-step03): Compute the joint covariance and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute covariance\n",
    "[mu_epsz, sig2_epsz] = meancov_sp(np.hstack((eps, z)))  # compute covariance between ε and Z\n",
    "sig2_eps = sig2_epsz[:n_, :n_]  # variance of ε\n",
    "sig2_z = sig2_epsz[n_:, n_:]  # variance of Z\n",
    "\n",
    "# compute correlation\n",
    "c2_epsz, _ = cov_2_corr(sig2_epsz)  #  compute correlation between ε and Z\n",
    "c_epsz = c2_epsz[:n_, n_:]  \n",
    "c2_eps = np.tril(c2_epsz[:n_, :n_], -1)  # correlation among residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4](https://www.arpm.co/lab/redirect.php?permalink=s_reg_truncated_lfm-implementation-step04): Compute standard deviations of two portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = np.ones(n_) / n_  # equal weight portfolio\n",
    "w_2 = np.zeros(n_)  # long/short weight portfolio\n",
    "w_2[n_long] = 0.69158715  # long weight portfolio\n",
    "w_2[n_short] = np.array([-0.67752045, -0.01406671])  # short weight portfolio\n",
    "\n",
    "_, sig2_x = meancov_sp(x)  # compute historical covariance of Xt\n",
    "sig2_x_trunc = beta @ sig2_z @ beta.T + np.diag(np.diag(sig2_eps))  # truncated target covariance of Xt\n",
    "\n",
    "std_1 = np.sqrt(w_1.T @ sig2_x @ w_1)  # standard deviation of the equal weight portfolio from sig2_x\n",
    "std_trunc_1 = np.sqrt(w_1.T @ sig2_x_trunc @ w_1)  # standard deviation of the euqal weight portfolio from sig2_x_trunc\n",
    "\n",
    "std_2 = np.sqrt(w_2.T @ sig2_x @ w_2)  # standard deviation of the long/short weight portfolio from sig2_x\n",
    "std_trunc_2 = np.sqrt(w_2.T @ sig2_x_trunc @ w_2)  # standard deviation of the long/short weight portfolio from sig2_x_trunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# (untruncated) correlations among residuals\n",
    "corr_eps = c2_eps[np.nonzero(c2_eps)]  # reshape the correlations\n",
    "n, xout = histogram_sp(corr_eps)\n",
    "\n",
    "mydpi = 72.0\n",
    "fig = plt.figure(figsize=(1280.0/mydpi,720.0/mydpi),dpi=mydpi)\n",
    "ax0 = plt.axes([0.595, 0.83, 0.92, 0.45])\n",
    "ax0.plot(corr_eps.mean(),0,'ro')\n",
    "plt.xlim(-0.6, 1.6)\n",
    "plt.ylim(0, 7)\n",
    "h = ax0.bar(xout, n, width=xout[1]-xout[0], facecolor=[.7, .7, .7], edgecolor='k')\n",
    "plt.text(0.24, 6.2, r'$\\mathbb{C}$' + r'$r$' + r'$\\{\\.ε_m\\, \\.ε_n\\}$',\n",
    "         fontsize=20)\n",
    "plt.xlabel(r'Correlation values', fontsize=17)\n",
    "plt.ylabel(r'Frequencies', fontsize=17)\n",
    "ax0.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.title('Cross correlations in regression LFM')\n",
    "\n",
    "c2_x, _ = cov_2_corr(sig2_x)\n",
    "c2_x = np.tril(c2_x[:n_, :n_], -1)\n",
    "corr_x = c2_x[np.nonzero(c2_x)]  # reshape the correlations\n",
    "n, xout = histogram_sp(corr_x)\n",
    "\n",
    "ax1 = plt.axes([0.595, 0.3, 0.92, 0.45])\n",
    "plt.xlim(-0.6, 1.6)\n",
    "plt.ylim(0, 4)\n",
    "ax1.plot(corr_x.mean(),0,'ro')\n",
    "ax1.axes.get_xaxis().set_ticks([])\n",
    "h1 = ax1.bar(xout, n, width=xout[1]-xout[0], facecolor=[.7, .7, .7], edgecolor='k')\n",
    "plt.ylabel(r'Frequencies', fontsize=17)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.text(0.6, 3.8, r'$\\mathbb{C}$' + r'$r$' + r'$\\{X_{m,t}, X_{n,t}\\}$',\n",
    "         fontsize=20)\n",
    "ax1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "add_logo(fig, location=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

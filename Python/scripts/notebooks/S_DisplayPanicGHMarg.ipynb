{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_DisplayPanicGHMarg [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_DisplayPanicGHMarg&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-2-pani-cop-ghmarg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange, zeros, percentile, diff, round, log, exp, corrcoef\n",
    "from numpy import sum as npsum\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, bar, scatter, ylabel, \\\n",
    "    xlabel, title\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from ARPM_utils import save_plot, struct_to_dict\n",
    "from intersect_matlab import intersect\n",
    "from HistogramFP import HistogramFP\n",
    "from ConditionalFP import ConditionalFP\n",
    "from PanicTDistribution import PanicTDistribution\n",
    "from CopMargSep import CopMargSep\n",
    "from ColorCodedFP import ColorCodedFP\n",
    "from GHCalibration import GHCalibration\n",
    "\n",
    "# inputs\n",
    "j_ = 1000  # number of simulations\n",
    "nb = round(5*log(j_))\n",
    "\n",
    "nu = 3  # degree of freedom\n",
    "r = 0.95  # panic correlation\n",
    "c = 0.07  # threshold\n",
    "\n",
    "# Load daily observations of the stocks in S&P 500\n",
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_StocksS_P'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_StocksS_P'), squeeze_me=True)\n",
    "\n",
    "Data = struct_to_dict(db['Data'])\n",
    "\n",
    "V = Data.Prices\n",
    "pair = [0, 1]  # stocks to spot\n",
    "\n",
    "# Set the calm correlation matrix as sample correlation matrix of compounded returns\n",
    "C = diff(log(V), 1, 1)\n",
    "C = C[pair, :]\n",
    "varrho2 = corrcoef(C)\n",
    "\n",
    "# Compute panic distribution\n",
    "X, p_ = PanicTDistribution(varrho2, r, c, nu, j_)\n",
    "\n",
    "# Extract the simulations of the panic copula\n",
    "x, u, U = CopMargSep(X, p_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the observations of VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_VIX'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_VIX'), squeeze_me=True)\n",
    "\n",
    "VIX = struct_to_dict(db['VIX'])\n",
    "\n",
    "Z = VIX.value\n",
    "Vdates = VIX.Date\n",
    "dates_Stocks = Data.Dates\n",
    "\n",
    "# match the db\n",
    "Dates, i_c, i_vix = intersect(dates_Stocks[1:], Vdates)\n",
    "C = C[:, i_c]\n",
    "Z_VIX = Z[i_vix]\n",
    "\n",
    "n_, t_ = C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Historical distribution with Flexible Probabilities conditioned on the VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.0005\n",
    "\n",
    "# exponential decay Flexible Probabilities (prior)\n",
    "prior = zeros((1, t_))\n",
    "for t in range(t_):\n",
    "    prior[0,t] = exp(-(t_ - t)*lam)\n",
    "\n",
    "prior = prior / npsum(prior)\n",
    "VIX = namedtuple('VIX', 'Series TargetValue Leeway')\n",
    "VIX.Series = Z_VIX.reshape(1,-1)\n",
    "VIX.TargetValue = np.atleast_2d(percentile(Z_VIX, 100 * 0.7))\n",
    "VIX.Leeway = 0.3\n",
    "\n",
    "p = ConditionalFP(VIX, prior)  # FP conditioned on the VIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the g&h inverse cdf to the Historical quantiles via Flexible Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step of local search\n",
    "Da0 = 1.0e-4\n",
    "Db0 = 1.0e-4\n",
    "Dg0 = 1.0e-4\n",
    "Dh0 = 1.0e-4\n",
    "\n",
    "Tolerance = 1.0e-8\n",
    "MaxItex = 10000  # maximun number of iterations\n",
    "\n",
    "aGH, bGH, gGH, hGH, SqDistGH, iterGH = GHCalibration(C, p, Tolerance, Da0, Db0, Dg0, Dh0, MaxItex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the simulations of the g&h Marginals by feeding the panic copula to the g&h inverse cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = zeros((n_, j_))\n",
    "for n in range(n_):\n",
    "    Y[n, :] = aGH[n] + bGH[n]*((1 / gGH[n])*(exp(gGH[n]*norm.ppf(U[n, :], 0, 1)) - 1)\n",
    "                               *exp(0.5*hGH[n]*norm.ppf(U[n, :], 0, 1) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent the scatter-plot and plot the histograms of the g&h marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "figure()\n",
    "grey_range = arange(0,0.81,0.01)\n",
    "CM, C = ColorCodedFP(p_, None, None, grey_range, 0, 18, [17, 5])\n",
    "# colormap(CM)\n",
    "scatter(Y[0], Y[1], s=3, c=C, marker='.',cmap=CM)\n",
    "xlabel('$Y_1$')\n",
    "ylabel('$Y_2$')\n",
    "title('g&h distribution');\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])\n",
    "\n",
    "# g&h marginal Y1\n",
    "figure()\n",
    "option = namedtuple('option', 'n_bins')\n",
    "option.n_bins = nb\n",
    "n1, c1 = HistogramFP(Y[[0]], p_, option)\n",
    "bar(c1[:-1], n1[0], width=c1[1]-c1[0], facecolor=[.9, .9, .9], edgecolor=  'k')\n",
    "title('Marginal $Y_1$');\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])\n",
    "\n",
    "# g&h marginal Y2\n",
    "figure()\n",
    "n2, varrho2 = HistogramFP(Y[[1]], p_, option)\n",
    "bar(varrho2[:-1], n2[0], width=varrho2[1]-varrho2[0], facecolor=[.9, .9, .9], edgecolor=  'k')\n",
    "title('Marginal $Y_2$');\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

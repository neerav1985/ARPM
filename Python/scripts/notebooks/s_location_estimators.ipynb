{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_location_estimators [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_location_estimators&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=ExermuEstimDist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arpym.tools.histogram_sp import histogram_sp\n",
    "from arpym.tools.logo import add_logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_location_estimators-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ = 15  # length of the time series\n",
    "j_ = 10 ** 3  # number of simulations\n",
    "mu = 2  # true value of the parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_location_estimators-implementation-step01): Generate simulations of the time series of invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_mu = stats.norm.rvs(mu, 1, (j_, t_))  # simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_location_estimators-implementation-step02): Sample mean computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hat = np.mean(i_mu, axis=1)  # simulations\n",
    "exp_m = np.mean(m_hat)  # expectation\n",
    "bias2_m = (exp_m - mu) ** 2  # square bias\n",
    "inef_m = np.std(m_hat, ddof=1)  # inefficiency\n",
    "\n",
    "l_m = (m_hat - mu) ** 2  # loss\n",
    "er_m = np.mean(l_m)  # error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_location_estimators-implementation-step03): Product estimator computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_hat = i_mu[:, 0] * i_mu[:, -1]  # simulations\n",
    "exp_pi = np.mean(pi_hat)  # expectation\n",
    "bias2_pi = (exp_pi - mu) ** 2  # square bias\n",
    "inef_pi = np.std(pi_hat, ddof=1)  # inefficiency\n",
    "\n",
    "l_pi = (pi_hat - mu) ** 2  # loss\n",
    "er_pi = np.mean(l_pi)  # error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4](https://www.arpm.co/lab/redirect.php?permalink=s_location_estimators-implementation-step04): Constant estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_hat = 3*np.ones(j_)  # simulations\n",
    "exp_k = np.mean(k_hat)  # expectation\n",
    "bias2_k = (exp_k - mu) ** 2  # square bias\n",
    "inef_k = np.std(k_hat, ddof=1)  # inefficiency\n",
    "\n",
    "l_k = (k_hat - mu) ** 2  # loss\n",
    "er_k = np.mean(l_k)  # error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('arpm')\n",
    "\n",
    "l_ = 125\n",
    "x = np.linspace(mu - 4, mu+4, l_)\n",
    "\n",
    "f_epsi = stats.norm.pdf(x, mu, 1)  # invariants' pdf\n",
    "\n",
    "# histograms computations\n",
    "\n",
    "# compute histogram\n",
    "# sample mean histograms\n",
    "m_hist, m_x = histogram_sp(m_hat)\n",
    "# product estimator histograms\n",
    "pi_hist, pi_x = histogram_sp(pi_hat)\n",
    "# constant estimator histograms\n",
    "k_hist, k_x = histogram_sp(k_hat.T, xi=np.arange(-33, 36))\n",
    "\n",
    "l_m_hist, l_m_x = histogram_sp(l_m)\n",
    "l_pi_hist, l_pi_x = histogram_sp(l_pi)\n",
    "l_k_hist, l_k_x = histogram_sp(l_k, xi=np.arange(-33, 36))\n",
    "\n",
    "colhist = [.8, .8, .8]\n",
    "orange = [1, 0.4, 0]\n",
    "green = [0.1, 0.8, 0]\n",
    "dark = [0.2, 0.2, 0.2]\n",
    "blue = [0, 0.4, 1]\n",
    "\n",
    "# histogram of invariants\n",
    "fig1 = plt.figure()\n",
    "heps = plt.plot(x, f_epsi, color=blue, lw=1.5)\n",
    "plt.plot([mu, mu], [0, 0], color=green, marker='o', markersize=6,\n",
    "         markerfacecolor=green)\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.title('TRUE (UNKNOWN) DISTRIBUTION')\n",
    "epsT = '$\\mu$ =  % 3.2f' % mu\n",
    "plt.text(np.min(x)+0.1, np.max(f_epsi)*0.95 - 0.001,\n",
    "         '$\\epsilon_{t} \\sim$ N(%s,$\\sigma^2$ = 1)' % epsT, color='k',\n",
    "         horizontalalignment='left')\n",
    "add_logo(fig1, location=1)\n",
    "plt.tight_layout()\n",
    "\n",
    "# histograms of estimators\n",
    "fig2, ax = plt.subplots(1, 3)\n",
    "# sample mean\n",
    "plt.sca(ax[0])\n",
    "hm = plt.bar(m_x, m_hist, width=m_x[1]-m_x[0], facecolor=colhist,\n",
    "             edgecolor='k')\n",
    "plt.plot([exp_m, exp_m], [0, 0], color=orange, marker='o', markersize=6,\n",
    "         markerfacecolor=orange)\n",
    "plt.plot([mu, exp_m], [0, 0], color=orange, lw=6)\n",
    "plt.plot([exp_m - inef_m, exp_m + inef_m], [np.max(m_hist)*0.02,\n",
    "         np.max(m_hist)*0.02], color=blue, lw=4)\n",
    "plt.plot([mu, mu], [0, 0], color=green, marker='o', markersize=6,\n",
    "         markerfacecolor=green)\n",
    "plt.xlim([np.percentile(m_hat, 100 * 0.0001), np.percentile(m_hat,\n",
    "          100 * 0.9999)])\n",
    "plt.xlabel('sample mean')\n",
    "\n",
    "# constant estimator\n",
    "plt.sca(ax[1])\n",
    "hk = plt.bar(k_x, k_hist / np.sum(k_hist), width=0.3,\n",
    "             facecolor=colhist, edgecolor='k')\n",
    "plt.plot([exp_k, exp_k], [0, 0], color=orange, marker='o', markersize=6,\n",
    "         markerfacecolor=orange)\n",
    "bias_plot = plt.plot([mu, exp_k], [0, 0], color=orange, lw=4)\n",
    "inef_plot = plt.plot([exp_k - inef_k, exp_k + inef_k], [np.max(k_hist)*0.02,\n",
    "                     np.max(k_hist)*0.02], color=blue, lw=4)\n",
    "plt.plot([mu, mu], [0, 0], color=green, marker='o', markersize=6,\n",
    "         markerfacecolor=green)\n",
    "plt.xlim([min([mu, 3]) - abs((mu - 3))*1.1, max([mu, 3]) + abs((mu - 3))*1.1])\n",
    "plt.xlabel('constant')\n",
    "plt.title('ESTIMATORS DISTRIBUTION')\n",
    "\n",
    "# product estimator\n",
    "plt.sca(ax[2])\n",
    "hpi = plt.bar(pi_x, pi_hist, width=pi_x[1]-pi_x[0], facecolor=colhist,\n",
    "              edgecolor='k')\n",
    "plt.plot([exp_pi, exp_pi], [0, 0], color=orange, marker='o', markersize=6,\n",
    "         markerfacecolor=orange)\n",
    "plt.plot([mu, exp_pi], [0, 0], color=orange, lw=4)\n",
    "plt.plot([exp_pi - inef_pi, exp_pi + inef_pi], [np.max(pi_hist)*0.02,\n",
    "         np.max(pi_hist)*0.02], color=blue, lw=4)\n",
    "plt.plot([mu, mu], [0, 0], color=green, marker='o', markersize=6,\n",
    "         markerfacecolor=green)\n",
    "plt.xlim([np.percentile(pi_hat, 100 * 0.001), np.percentile(pi_hat,\n",
    "          100 * 0.999)])\n",
    "plt.xlabel('first-last product')\n",
    "plt.legend(handles=[bias_plot[0], inef_plot[0]], labels=['bias', 'ineff.'])\n",
    "add_logo(fig2, location=5, size_frac_x=1/5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# histograms of square losses\n",
    "fig3, ax = plt.subplots(1, 3)\n",
    "# sample mean\n",
    "plt.sca(ax[0])\n",
    "hLm = plt.bar(l_m_x, l_m_hist, width=l_m_x[1]-l_m_x[0],\n",
    "              facecolor=colhist, edgecolor='k')\n",
    "plt.plot([0, bias2_m], [0.002, 0.002], color=orange, lw=5)\n",
    "plt.plot([bias2_m, er_m], [0.002, 0.002], color=blue, lw=5)\n",
    "plt.plot([0, er_m], [np.max(l_m_hist)*0.0275, np.max(l_m_hist)*0.0275],\n",
    "         color=dark, lw=5)\n",
    "plt.plot([0, 0], [0, 0], color=green, marker='o', markersize=6,\n",
    "         markerfacecolor=green)\n",
    "plt.xlim([-max(l_m)*0.005, np.percentile(l_m, 100 * 0.95)])\n",
    "plt.xlabel('sample mean')\n",
    "# constant estimator\n",
    "plt.sca(ax[1])\n",
    "hLk = plt.bar(l_k_x, l_k_hist / np.sum(l_k_hist), width=0.1,\n",
    "              facecolor=colhist, edgecolor='none')\n",
    "plt.plot([0, bias2_k], [0.001, 0.001], color=orange, lw=5)\n",
    "plt.plot([bias2_k, er_k], [0.001, 0.001], color=blue, lw=5)\n",
    "plt.plot([0, er_k], [np.max(l_k_hist)*0.0275, np.max(l_k_hist)*0.0275],\n",
    "         color=dark, lw=5)\n",
    "plt.plot([0, 0], [0, 0], color=green, marker='o', markersize=6,\n",
    "         markerfacecolor=green)\n",
    "plt.xlim([-0.01, 1.25*(mu - 3) ** 2])\n",
    "plt.xlabel('constant')\n",
    "plt.title('LOSS DISTRIBUTION')\n",
    "# product estimator\n",
    "plt.sca(ax[2])\n",
    "hLpi = plt.bar(l_pi_x, l_pi_hist, width=l_pi_x[1]-l_pi_x[0],\n",
    "               facecolor=colhist, edgecolor='k')\n",
    "bias_plot = plt.plot([0, bias2_pi], [0.001, 0.001], color=orange, lw=5,\n",
    "                     zorder=2)\n",
    "inef_plot = plt.plot([bias2_pi, er_pi], [0.001, 0.001], color=blue, lw=5,\n",
    "                     zorder=1)\n",
    "error_plot = plt.plot([0, er_pi], [np.max(l_pi_hist)*0.0275,\n",
    "                 np.max(l_pi_hist)*0.0275], color=dark, lw=5, zorder=1)\n",
    "plt.plot([0, 0], [0, 0], color=green, marker='o', markersize=6,\n",
    "         markerfacecolor=green)\n",
    "plt.xlim([-max(l_pi)*0.005, np.percentile(l_pi, 100 * 0.95)])\n",
    "plt.xlabel('first-last product')\n",
    "plt.legend(handles=[error_plot[0], bias_plot[0], inef_plot[0]],\n",
    "           labels=['error', 'bias$^2$', 'ineff.$^2$'])\n",
    "add_logo(fig3, location=5, size_frac_x=1/5)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

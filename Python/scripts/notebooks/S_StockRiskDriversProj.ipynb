{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_StockRiskDriversProj [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_StockRiskDriversProj&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-garchdccinv-proj)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange, zeros, argsort, diff, diag, eye, abs, log, exp, sqrt, tile, array\n",
    "from numpy import sum as npsum\n",
    "from numpy.linalg import cholesky, pinv\n",
    "\n",
    "from scipy.stats import t as tstu\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from ARPM_utils import struct_to_dict\n",
    "from intersect_matlab import intersect\n",
    "from ConditionalFP import ConditionalFP\n",
    "from MaxLikelihoodFPLocDispT import MaxLikelihoodFPLocDispT\n",
    "from FactorAnalysis import FactorAnalysis\n",
    "from Tscenarios import Tscenarios\n",
    "\n",
    "# parameters\n",
    "\n",
    "tauHL_smoo = 30  # half-life time for smoothing\n",
    "tauHL_scor = 100  # half-life time for scoring\n",
    "\n",
    "alpha = 0.25\n",
    "tauHL_prior = 21*4  # parameters for Flexible Probabilities conditioned on VIX\n",
    "\n",
    "nu_vec = arange(2,31)\n",
    "nu_ = len(nu_vec)\n",
    "\n",
    "nu_copula = 15  # degrees of freedom of t copula\n",
    "k_ = 15  # factors for dimension reduction\n",
    "m_ = 5  # monitoring times\n",
    "j_ = 10  # number of scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_S&P500GARCHDCCInv'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_S&P500GARCHDCCInv'), squeeze_me=True)\n",
    "\n",
    "dates = db['dates']\n",
    "epsi_stocks = db['epsi_stocks']\n",
    "q2_last= db['q2_last']\n",
    "a_DCC = db['a_DCC']\n",
    "b_DCC = db['b_DCC']\n",
    "c_DCC = db['c_DCC']\n",
    "sig2_GARCH = db['sig2_GARCH']\n",
    "par_GARCH = db['par_GARCH']\n",
    "deltax = db['deltax']\n",
    "\n",
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_VIX'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_VIX'), squeeze_me=True)\n",
    "\n",
    "VIX = struct_to_dict(db['VIX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the projected path scenarios via copula marginal/Monte Carlo approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible probabilities\n",
    "\n",
    "# time series of conditioning variable (smoothed and scored VIX's\n",
    "# compounded returns)\n",
    "c_VIX = diff(log(VIX.value))\n",
    "t_vix = len(c_VIX)\n",
    "times = range(t_vix)\n",
    "\n",
    "# smoothing\n",
    "z_vix = zeros((1, t_vix))\n",
    "for t in range(t_vix):\n",
    "    p_smoo_t = exp(-log(2)/tauHL_smoo*(tile(t+1, (1, t+1))-times[:t+1]))\n",
    "    gamma_t = npsum(p_smoo_t)\n",
    "    z_vix[0,t] = npsum(p_smoo_t * c_VIX[:t+1]) / gamma_t\n",
    "\n",
    "# scoring\n",
    "mu_hat = zeros((1, t_vix))\n",
    "mu2_hat = zeros((1, t_vix))\n",
    "sd_hat = zeros((1, t_vix))\n",
    "for t in range(t_vix):\n",
    "    p_scor_t = exp(-log(2) / tauHL_scor*(tile(t+1, (1, t+1))-times[:t+1]))\n",
    "    gamma_scor_t = npsum(p_scor_t)\n",
    "    mu_hat[0,t] = npsum(p_scor_t * z_vix[0,:t+1]) / gamma_scor_t\n",
    "    mu2_hat[0,t] = npsum(p_scor_t * (z_vix[0,:t+1]) ** 2) / gamma_scor_t\n",
    "    sd_hat[0,t] = sqrt(mu2_hat[0,t]-(mu_hat[0,t]) ** 2)\n",
    "\n",
    "z_vix = (z_vix - mu_hat) / sd_hat\n",
    "\n",
    "# time series of invariants and VIX time series matching\n",
    "dates_stocks, tau_vix, tau_stock = intersect(VIX.Date[1:], dates)\n",
    "epsi_stocks = epsi_stocks[:, tau_stock]\n",
    "z_vix = z_vix[[0],tau_vix]\n",
    "z_vix_star = z_vix[-1]  # target value\n",
    "i_, t_ = epsi_stocks.shape\n",
    "\n",
    "# state and time conditioned probabilities\n",
    "prior = exp(-log(2) / tauHL_prior*abs(arange(t_, 1 + -1, -1))).reshape(1,-1)\n",
    "prior = prior / npsum(prior)\n",
    "\n",
    "# conditioner\n",
    "conditioner = namedtuple('conditioner', ['Series', 'TargetValue', 'Leeway'])\n",
    "conditioner.Series = z_vix.reshape(1,-1)\n",
    "conditioner.TargetValue = np.atleast_2d(z_vix_star)\n",
    "conditioner.Leeway = alpha\n",
    "\n",
    "p = ConditionalFP(conditioner, prior)\n",
    "\n",
    "# marginal distribution fit\n",
    "nu_marg = zeros(i_)\n",
    "mu_marg = zeros(i_)\n",
    "sig2_marg = zeros(i_)\n",
    "for i in range(i_):\n",
    "    mu_nu = zeros(nu_)\n",
    "    sig2_nu = zeros(nu_)\n",
    "    like_nu = zeros((1, nu_))\n",
    "    for k in range(nu_):\n",
    "        nu = nu_vec[k]\n",
    "        mu_nu[k], sig2_nu[k],_ = MaxLikelihoodFPLocDispT(epsi_stocks[[i],:], p, nu, 10 ** -6, 1)\n",
    "        epsi_t = (epsi_stocks[i,:]-mu_nu[k]) / sqrt(sig2_nu[k])\n",
    "        like_nu[0,k] = npsum(p * log(tstu.cdf(epsi_t, nu) / sqrt(sig2_nu[k])))\n",
    "\n",
    "    k_nu = argsort(like_nu[0])[::-1]\n",
    "    nu_marg[i] = max(nu_vec[k_nu[0]], 10)\n",
    "    mu_marg[i] = mu_nu[k_nu[0]]\n",
    "    sig2_marg[i] = sig2_nu[k_nu[0]]\n",
    "\n",
    "# Realized marginals mapping into standard Student t realizations\n",
    "u_stocks = zeros((i_, t_))\n",
    "epsi_tilde_stocks = zeros((i_, t_))\n",
    "for i in range(i_):\n",
    "    # u_stocks([i,:])=min((t.cdf((epsi_stocks[i,:]-mu_marg[i])/sqrt(sig2_marg[i]),nu_marg[i]),0.999))\n",
    "    u_stocks[i,:]=tstu.cdf((epsi_stocks[i,:]-mu_marg[i]) / sqrt(sig2_marg[i]), nu_marg[i])\n",
    "    epsi_tilde_stocks[i,:] = tstu.ppf(u_stocks[i,:], nu_copula)  # Student t realizations\n",
    "\n",
    "# Correlation matrix characterizing the t copula estimation\n",
    "\n",
    "# approximate the fit to normal in case of badly scaled warnings\n",
    "_, sig2,_ = MaxLikelihoodFPLocDispT(epsi_tilde_stocks, p, 1e9, 1e-6, 1)\n",
    "rho2 = np.diagflat(diag(sig2) ** (-1 / 2))@sig2@np.diagflat(diag(sig2) ** (-1 / 2))\n",
    "\n",
    "# Shrink the correlation matrix towards a low-rank-diagonal structure\n",
    "rho2, beta, *_ = FactorAnalysis(rho2, array([[0]]), k_)\n",
    "rho2, beta = np.real(rho2), np.real(beta)\n",
    "\n",
    "# Monte Carlo scenarios for each path node from the t copula\n",
    "Epsi_tilde_hor = zeros((i_, m_, j_))\n",
    "optionT = namedtuple('option', 'dim_red stoc_rep')\n",
    "optionT.dim_red = 0\n",
    "optionT.stoc_rep = 0\n",
    "for m in range(m_):\n",
    "    Epsi_tilde_hor[:,m,:]=Tscenarios(nu_copula, zeros((i_, 1)), rho2, j_, optionT)  # We simulate scenarios one node at a time\n",
    "\n",
    "# Projected path scenarios\n",
    "Epsi_stocks_hor = zeros((i_, m_, j_))\n",
    "U_stocks_hor = zeros((i_, m_, j_))\n",
    "for i in range(i_):\n",
    "    for m in range(m_):\n",
    "        U_stocks_hor[i, m,:]=tstu.cdf(Epsi_tilde_hor[i, m,:], nu_copula)\n",
    "        Epsi_stocks_hor[i, m,:]=mu_marg[i] + sqrt(sig2_marg[i])*tstu.ppf(U_stocks_hor[i, m,:], nu_marg[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the projected path scenarios for the quasi-invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse correlation matrix\n",
    "delta2 = diag(eye(i_) - beta@beta.T)\n",
    "omega2 = np.diagflat(1 / delta2)\n",
    "rho2_inv = omega2 - omega2@beta.dot(pinv(beta.T@omega2@beta + eye(k_)))@beta.T@omega2\n",
    "\n",
    "Xi = zeros((i_,m_,j_))\n",
    "# quasi invariants\n",
    "for j in range(j_):\n",
    "    for m in range(m_):\n",
    "        if m == 0:\n",
    "            q2_prior=q2_last\n",
    "            q2=c_DCC*rho2+b_DCC*q2_prior+a_DCC*epsi_stocks[:,-1]@epsi_stocks[:, -1].T\n",
    "        else:\n",
    "            q2 = c_DCC*rho2 + b_DCC*q2_prior + a_DCC*Epsi_stocks_hor[:, m, j]@Epsi_stocks_hor[:, m, j].T\n",
    "\n",
    "        r2 = np.diagflat(diag(q2) ** (-1 / 2))@q2@np.diagflat(diag(q2) ** (-1 / 2))\n",
    "        Xi[:, m, j]=cholesky(r2)@rho2_inv@Epsi_stocks_hor[:, m, j]\n",
    "        q2_prior = q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the projected path scenarios of the risk drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hor = zeros((i_, m_, j_))\n",
    "for i in range(i_):\n",
    "    for j in range(j_):\n",
    "        for m in range(m_):\n",
    "            if m == 0:\n",
    "                dX_hor_prior=deltax[i,-1]-deltax[i, -2]\n",
    "                Sig2_prior=sig2_GARCH[i, -1]\n",
    "                Sig2=par_GARCH[0, i]+par_GARCH[1, i]*Sig2_prior+par_GARCH[2, i]*dX_hor_prior**2\n",
    "                X_hor[i, m, j]=sqrt(Sig2)*Xi[i, m, j]\n",
    "            elif m == 1:\n",
    "                dX_hor_prior = X_hor[i, m - 1, j] - deltax[i,-1]\n",
    "                Sig2_prior = Sig2\n",
    "                Sig2 = par_GARCH[0, i] + par_GARCH[1, i]*Sig2_prior + par_GARCH[2, i]*dX_hor_prior**2\n",
    "                X_hor[i, m, j] = sqrt(Sig2)*Xi[i, m, j]\n",
    "            else:\n",
    "                dX_hor_prior = X_hor[i, m - 1, j] - X_hor[i, m - 2, j]\n",
    "                Sig2_prior = Sig2\n",
    "                Sig2 = par_GARCH[0, i] + par_GARCH[1, i]*Sig2_prior + par_GARCH[2, i]*dX_hor_prior**2\n",
    "                X_hor[i, m, j] = sqrt(Sig2)*Xi[i, m, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_to_save = ['Epsi_stocks_hor','X_hor','U_stocks_hor','nu_marg','mu_marg','sig2_marg','epsi_stocks','dates_stocks']\n",
    "vars_to_save = {varname: var for varname, var in locals().items() if isinstance(var,(np.ndarray,np.float,np.int))}\n",
    "vars_to_save = {varname: var for varname, var in vars_to_save.items() if varname in varnames_to_save}\n",
    "savemat(os.path.join(TEMPORARY_DB, 'db_GARCHDCCMCProj'),vars_to_save)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

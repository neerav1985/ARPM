{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_GenCrossSectionEstimLFM [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_GenCrossSectionEstimLFM&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-3-ex-unc-cross-sec)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy import reshape, ones, zeros, tril, diag, eye, round, log, tile, r_\n",
    "\n",
    "from scipy.linalg import kron\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, bar, title\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from ARPM_utils import save_plot\n",
    "from FPmeancov import FPmeancov\n",
    "from HistogramFP import HistogramFP\n",
    "from quadprog import quadprog\n",
    "\n",
    "# input parameters\n",
    "n_ = 100  # target dimension\n",
    "k_ = 10  # number of factors\n",
    "i_n = eye(n_)\n",
    "i_k = eye(k_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weekly observations of the stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_Securities_TS'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_Securities_TS'), squeeze_me=True)\n",
    "\n",
    "data = db['data']\n",
    "data_securities = data[1:,:]  # 1st row is date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sector-securities binary exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_Securities_IndustryClassification'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_Securities_IndustryClassification'), squeeze_me=True)\n",
    "\n",
    "data = db['data']\n",
    "securities_industry_classification = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute linear returns of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = data_securities[:n_,:]  # values\n",
    "R = (V[:, 1:] - V[:, : -1]) / V[:, : -1]\n",
    "_, t_ = R.shape\n",
    "p = ones((1, t_)) / t_  # Flexible Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the exogenous loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = securities_industry_classification[:n_,:k_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve quadratic programming problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = zeros((k_*n_, k_*n_))  # commutation matrix\n",
    "for n in range(n_):\n",
    "    for k in range(k_):\n",
    "        km = km + kron(i_k[:,[k]]@i_n[:, [n]].T, i_n[:,[n]] @i_k[:, [k]].T)  # set inputs for quadratic programming problem\n",
    "\n",
    "[m_R, s2_R] = FPmeancov(R, p)\n",
    "invsigma2 = np.diagflat(1 / diag(s2_R))\n",
    "pos = beta.T@invsigma2@s2_R\n",
    "g = -pos.flatten('F')\n",
    "q = kron(s2_R, beta.T@invsigma2@beta)\n",
    "q_, _ = q.shape\n",
    "\n",
    "# linear constraints\n",
    "v = ones((1, n_)) / n_\n",
    "d_eq = kron(i_k, v@s2_R)@km\n",
    "b_eq = zeros((k_, 1))\n",
    "\n",
    "# compute extraction matrix\n",
    "c = quadprog(q, g, d_eq, b_eq)\n",
    "\n",
    "gamma = reshape(c, (k_, n_),'F')\n",
    "Z = gamma@R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute shift parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mu_Z, sig2_Z] = FPmeancov(Z, p)\n",
    "\n",
    "alpha = m_R - beta@mu_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = R - tile(alpha, (1, t_)) - beta@Z\n",
    "[mu_UZ, sig2_UZ] = FPmeancov(r_[U, Z], p)  # sample joint covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute correlations between factors and residuals, and correlations among residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_UZ = np.diagflat(diag(sig2_UZ) ** (-1 / 2))@sig2_UZ@np.diagflat(diag(sig2_UZ) ** (-1 / 2))\n",
    "\n",
    "c_UZ = c2_UZ[:n_, n_ :n_ + k_]\n",
    "c2_U = tril(c2_UZ[:n_, :n_], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute truncated covariance of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig2_U = sig2_UZ[:n_, :n_]\n",
    "sig2_Rtrunc = beta@sig2_Z@beta.T + np.diagflat(diag(sig2_U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot (untruncated) correlations among residuals\n",
    "## reshape the correlations in a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_U = []\n",
    "for i in range(1,n_):\n",
    "    corr_U = r_[corr_U, c2_U[i:,i-1]]  # ## reshape the correlations in a column vector\n",
    "corr_U = corr_U.reshape(-1,1)\n",
    "\n",
    "nbins = round(5*log(len(corr_U)))\n",
    "p = ones((1, len(corr_U))) / len(corr_U)\n",
    "option = namedtuple('option', 'n_bins')\n",
    "option.n_bins = nbins\n",
    "[n, xout] = HistogramFP(corr_U.T, p, option)\n",
    "\n",
    "figure()\n",
    "\n",
    "h = bar(xout[:-1], n[0], width=xout[1]-xout[0],facecolor= [.7, .7, .7], edgecolor='k')\n",
    "title('Correlation among residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot (untruncated) correlations between factors and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## reshape the correlations in a column vector\n",
    "\n",
    "corr_UZ = reshape(c_UZ, (n_*k_, 1),'F')\n",
    "p = ones((1, len(corr_UZ))) / len(corr_UZ)\n",
    "[n, xout] = HistogramFP(corr_UZ.T, p, option)\n",
    "\n",
    "figure()\n",
    "h = bar(xout[:-1], n[0], width=xout[1]-xout[0], facecolor= [.7, .7, .7], edgecolor='k')\n",
    "title('Correlation factors-residuals');\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

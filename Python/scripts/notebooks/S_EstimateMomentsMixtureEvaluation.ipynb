{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_EstimateMomentsMixtureEvaluation [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_EstimateMomentsMixtureEvaluation&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eSTaSSESSmOMbASED)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "from numpy import ones, zeros, round, mean, log, exp\n",
    "from numpy import max as npmax\n",
    "from numpy.random import rand\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, plot, bar, legend, subplots, title\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from ARPM_utils import save_plot\n",
    "from HistogramFP import HistogramFP\n",
    "from QuantileMixture import QuantileMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define estimators\n",
    "g_a = lambda X: (X[:, [0]] - X[:,[-1]]) *X[:, [1]] * X[:, [1]]\n",
    "g_b = lambda X: mean(X, 1, keepdims=True)\n",
    "g_c = lambda X: 5 + 0*X[:, [0]]\n",
    "g_d = lambda X: mean(X ** 2 - X, 1, keepdims=True)\n",
    "\n",
    "# generate the scenarios for the time series\n",
    "t_ = 50\n",
    "j_ = 10 ** 4\n",
    "alpha = 0.5\n",
    "mu_Y = 0.1\n",
    "sigma_Y = 0.2\n",
    "mu_Z = 0\n",
    "sigma_Z = 0.15\n",
    "\n",
    "# compute the true value of the property\n",
    "gamma = alpha*(mu_Y ** 2 + sigma_Y ** 2 - mu_Y) + (1 - alpha)*( exp(2*mu_Z + 2*sigma_Z ** 2) - exp(mu_Z + 0.5*sigma_Z ** 2))\n",
    "# generate j_ simulations of the time series\n",
    "I = zeros((j_, t_))\n",
    "P = rand(j_, t_)\n",
    "for t in range(t_):\n",
    "    I[:,t]= QuantileMixture(P[:,t], alpha, mu_Y, sigma_Y, mu_Z, sigma_Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute error, bias and inefficiency for every estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute simulations of the estimators\n",
    "G_a = g_a(I)\n",
    "G_b = g_b(I)\n",
    "G_c = g_c(I)\n",
    "G_d = g_d(I)\n",
    "# compute the losses of the estimators\n",
    "L_a = (G_a - gamma) ** 2\n",
    "L_b = (G_b - gamma) ** 2\n",
    "L_c = (G_c - gamma) ** 2\n",
    "L_d = (G_d - gamma) ** 2\n",
    "# compute errors\n",
    "er_a = mean(L_a)\n",
    "er_b = mean(L_b)\n",
    "er_c = mean(L_c)\n",
    "er_d = mean(L_d)\n",
    "# compute square bias\n",
    "bias2_a = (mean((G_a) - gamma)) ** 2\n",
    "bias2_b = (mean((G_b) - gamma)) ** 2\n",
    "bias2_c = (mean((G_c) - gamma)) ** 2\n",
    "bias2_d = (mean((G_d) - gamma)) ** 2\n",
    "# compute square inefficiency\n",
    "inef2_a = er_a - bias2_a\n",
    "inef2_b = er_b - bias2_b\n",
    "inef2_c = er_c - bias2_c\n",
    "inef2_d = er_d - bias2_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = [.7, .7, .7]\n",
    "dgray = [.5, .5, .5]\n",
    "red = [.9, .4, 0]\n",
    "blue = [0, .45, .7]\n",
    "\n",
    "# estimators.T distributionfigure()\n",
    "NumBins = round(7*log(j_))\n",
    "p = ones((1, j_)) / j_\n",
    "\n",
    "f, ax = subplots(4, 1)\n",
    "plt.sca(ax[0])\n",
    "option = namedtuple('option', 'n_bins')\n",
    "option.n_bins = NumBins\n",
    "n, x = HistogramFP(G_a.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "\n",
    "true = plot(gamma, 0, '.', markersize=15,color='g',label='true property value')\n",
    "title('estimator a')\n",
    "legend()\n",
    "\n",
    "plt.sca(ax[1])\n",
    "n, x = HistogramFP(G_b.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "\n",
    "plot(gamma, 0, '.',markersize= 15, color='g')\n",
    "title('estimator b')\n",
    "\n",
    "plt.sca(ax[2])\n",
    "n, x = HistogramFP(G_c.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "\n",
    "plot(gamma, 0, '.',markersize= 15, color='g')\n",
    "title('estimator c')\n",
    "\n",
    "plt.sca(ax[3])\n",
    "n, x = HistogramFP(G_d.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "plot(gamma, 0, '.', markersize=15, color='g')\n",
    "title('estimator d')\n",
    "plt.tight_layout();\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])\n",
    "\n",
    "# loss\n",
    "h1 = 0.035\n",
    "h = 0.01\n",
    "f, ax = subplots(4,1)\n",
    "plt.sca(ax[0])\n",
    "n, x = HistogramFP(L_a.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "title('loss of estimator a')\n",
    "plt.ylim([0,npmax(n)*1.1])\n",
    "error = plot([0, er_a], [npmax(n)*h1, npmax(n)*h1], color='k',lw=2)\n",
    "bias = plot([0, bias2_a], [npmax(n)*h, npmax(n)*h], color=red, lw=2)\n",
    "inefficiency = plot([bias2_a, er_a], [npmax(n)*h, npmax(n)*h], color=blue, lw=2)\n",
    "legend(['error', 'bias$^2$' , 'ineff$^2$'])\n",
    "\n",
    "plt.sca(ax[1])\n",
    "n, x = HistogramFP(L_b.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "title('loss of estimator b')\n",
    "plt.ylim([0,npmax(n)*1.1])\n",
    "plot([0, bias2_b], [npmax(n)*h, npmax(n)*h], color=red, lw=2)\n",
    "plot([0, er_b], [npmax(n)*h1, npmax(n)*h1], color='k',lw=2)\n",
    "plot([bias2_b, er_b], [npmax(n)*h, npmax(n)*h], color=blue, lw=2)\n",
    "\n",
    "plt.sca(ax[2])\n",
    "n, x = HistogramFP(L_c.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "title('loss of estimator c')\n",
    "plt.ylim([0,npmax(n)*1.1])\n",
    "plot([0, bias2_c], [npmax(n)*h, npmax(n)*h], color=red, lw=2)\n",
    "plot([0, er_c], [npmax(n)*h1, npmax(n)*h1], color='k',lw=2)\n",
    "plot([bias2_c, er_c], [npmax(n)*h, npmax(n)*h], color=blue, lw=2)\n",
    "\n",
    "plt.sca(ax[3])\n",
    "n, x = HistogramFP(L_d.T, p, option)\n",
    "b = bar(x[:-1],n[0], width=x[1]-x[0],facecolor=gray, edgecolor=dgray)\n",
    "title('loss of estimator d')\n",
    "plt.ylim([0, npmax(n)*1.1])\n",
    "plot([0, bias2_d], [npmax(n)*h, npmax(n)*h], color=red, lw=2)\n",
    "plot([0, er_d], [npmax(n)*h1, npmax(n)*h1], color='k',lw=2)\n",
    "plot([bias2_d, er_d], [npmax(n)*h, npmax(n)*h], color=blue, lw=2)\n",
    "plt.tight_layout();\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_ProjectionCompPoisson [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_ProjectionCompPoisson&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=ExerCompPoissExp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "from numpy import arange, array, ones, zeros, cumsum, round, log, exp, sqrt, unique, where, r_\n",
    "from numpy import sum as npsum, min as npmin, max as npmax\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, plot, legend, ylabel, \\\n",
    "    xlabel, title, xticks\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from ARPM_utils import save_plot, struct_to_dict\n",
    "from FPmeancov import FPmeancov\n",
    "from HistogramFP import HistogramFP\n",
    "from EffectiveScenarios import EffectiveScenarios\n",
    "from IterGenMetMomFP import IterGenMetMomFP\n",
    "from binningHFseries import binningHFseries\n",
    "from SimulateCompPoisson import SimulateCompPoisson\n",
    "from PathMomMatch import PathMomMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_US_10yr_Future_quotes_and_trades'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_US_10yr_Future_quotes_and_trades'), squeeze_me=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = struct_to_dict(db['trades'])\n",
    "\n",
    "trade_time = trades.time  # time vector of trades\n",
    "size = trades.siz  # flow of traded contracts' volumes\n",
    "\n",
    "# set projection variables\n",
    "tau = 10  # investment horizon\n",
    "dt = 1 / 20  # infinitesimal step for simulations\n",
    "t_j = arange(0, tau+dt,dt)  # time vector for simulations\n",
    "j_ = 3000  # number of simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the number of events dn and the traded volume dq at each 1-second interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_n = unique(trade_time)\n",
    "delta_q = zeros((1, len(t_n)))\n",
    "for k in range(len(t_n)):\n",
    "    index = trade_time == t_n[k]\n",
    "    delta_q[0,k] = sum(size[index])  # sum the traded volume relative to the same \"match event\"\n",
    "\n",
    "[dn, _, _, dq] = binningHFseries(t_n, '1second', delta_q)  # 1-second spacing\n",
    "q = cumsum(dq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the intensity of Poisson process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential decay FP\n",
    "lam1 = log(2) / 360\n",
    "p1 = exp(-lam1 * arange(dn.shape[1],0,-1)).reshape(1,-1)\n",
    "p1 = p1 / npsum(p1)  # FP-profile: exponential decay 1 years\n",
    "typ = namedtuple('type','Entropy')\n",
    "typ.Entropy = 'Exp'\n",
    "ens1 = EffectiveScenarios(p1, typ)\n",
    "# generalized method of moments\n",
    "Parameters = IterGenMetMomFP(dn, p1, 'Poisson')\n",
    "lam = Parameters.lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit jumps to an exponential distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential decay FP\n",
    "lam2 = log(2) / round(100*lam)\n",
    "p2 = exp(-lam2 * arange(dq.shape[1],0,-1)).reshape(1,-1)\n",
    "p2 = p2 / npsum(p2)  # FP-profile: exponential decay 1 years\n",
    "ens2 = EffectiveScenarios(p2, typ)\n",
    "# compute FP-mean and variance of an exponential distribution\n",
    "mu_dq, _ = FPmeancov(dq, p2)\n",
    "sigma2_dq = mu_dq ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute expectation and variance of the compound Poisson process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = lam*mu_dq\n",
    "sigma2 = lam*sigma2_dq\n",
    "sigma = sqrt(sigma2)\n",
    "\n",
    "# project to future times\n",
    "mu_tau = mu*t_j\n",
    "sigma_tau = sigma*sqrt(t_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the compound Poisson process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'ExpJumps'\n",
    "c = SimulateCompPoisson(lam, dq, p2, t_j.reshape(1,-1), j_, method)\n",
    "\n",
    "# path moment-matching via EP\n",
    "step = int(round(tau / (10*dt)))\n",
    "p0 = ones((1, j_)) / j_  # initial flat probabilities for the scenarios\n",
    "c_p = ones((j_, 1))  # constraint on probabilities\n",
    "c_mu = mu_tau[[0],step::step]  # constraint on expectation\n",
    "c_sigma2 = sigma_tau[[0],step::step] ** 2  # constraint on variance\n",
    "\n",
    "p, _ = PathMomMatch(p0, c[:, step::step].T,c_mu.T,c_sigma2.T,c_p.T)\n",
    "\n",
    "c = c + q[-1]  # centering simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project the pdf to horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = namedtuple('option', 'n_bins')\n",
    "option.n_bins = 200\n",
    "y_hor, x_hor = HistogramFP(c[:,[-1]].T, p, option)\n",
    "# normal approximation\n",
    "y_norm = norm.pdf(x_hor, q[-1] + mu_tau[0,-1], sigma_tau[0,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ = 2  # number of plotted observation before projecting time\n",
    "j_visual = 15  # number of simulated paths to be printed\n",
    "\n",
    "# axes settings\n",
    "c_sample = c[:j_visual,:]\n",
    "m = min([npmin(c_sample), q[-1]-2*sigma_tau[0,-1]])\n",
    "M = max([npmax(c_sample), q[-1] + mu_tau[0,-1]+3.5*sigma_tau[0,-1]])  #\n",
    "t = arange(-s_,tau+1)\n",
    "max_scale = tau / 4\n",
    "scale = max_scale / npmax(y_hor)\n",
    "\n",
    "# preliminary computations\n",
    "tau_red = arange(0,tau+0.1,0.1)\n",
    "mu_red = q[-1] + mu*tau_red\n",
    "sigma_red = sqrt(sigma2*tau_red)\n",
    "redline1 = mu_red + 2*sigma_red\n",
    "redline2 = mu_red - 2*sigma_red\n",
    "\n",
    "f = figure()\n",
    "# color settings\n",
    "lgrey = [0.8, 0.8, 0.8]\n",
    "# light grey\n",
    "dgrey = [0.55, 0.55, 0.55]\n",
    "# dark grey\n",
    "lblue = [0.27, 0.4, 0.9]\n",
    "# light blue\n",
    "plt.axis([t[0], t[-1] + max_scale, m, M])\n",
    "xlabel('time (seconds)')\n",
    "ylabel('Risk driver')\n",
    "xticks(r_[t[:s_+ 1], arange(t[-1]+1)])\n",
    "plt.grid(False)\n",
    "title('Compound Poisson Process')\n",
    "# simulated paths\n",
    "for j in range(j_visual):\n",
    "    plot(t_j, c[j,:], color = lgrey, lw = 2)\n",
    "# standard deviation lines\n",
    "p_red_1 = plot(tau_red, redline1[0], color='r', lw = 2, label='+ / - 2 st.deviation')  # red bars (+2 std dev)\n",
    "p_red_2 = plot(tau_red, redline2[0], color='r', lw = 2)  # red bars (-2std dev)\n",
    "p_mu = plot([0, tau], [q[-1], q[-1] + mu_tau[0,-1]], color='g', lw = 2, label='expectation')  # expectation\n",
    "# histogram pdf plot\n",
    "for k in range(y_hor.shape[1]):\n",
    "    f_hist = plot([tau, tau + y_hor[0,k]*scale],[x_hor[k], x_hor[k]], color = dgrey, lw=3, label='horizon pdf')  # normal approximation plot\n",
    "phi_border = plot(tau + y_norm*scale, x_hor, color=lblue, lw=1, label='Normal approximation')\n",
    "# plot of last s_ observations\n",
    "for k in range(s_):\n",
    "    plot([t[k], t[k+1]], [q[-s_+k-1], q[-s_+k-1]], color=lgrey, lw=2)\n",
    "    plot(t[k], q[-s_+k-1], color='b',linestyle='none', marker='.',markersize=15)\n",
    "plot(t[s_], q[-1], color='b',linestyle='none', marker='.',markersize=15)\n",
    "plot([tau, tau], q[-1]+mu_tau[0,-1]+array([-2*sigma_tau[0,-1], +2*sigma_tau[0,-1]]), color='r', lw=2)\n",
    "# leg\n",
    "legend(handles=[f_hist[0],p_red_1[0],p_mu[0], phi_border[0]], labels=['horizon pdf', '+ / - 2 st.deviation','expectation','Normal approximation']);\n",
    "# save_plot(ax=plt.gca(), extension='png', scriptname=os.path.basename('.')[:-3], count=plt.get_fignums()[-1])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

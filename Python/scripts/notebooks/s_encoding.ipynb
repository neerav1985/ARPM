{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s_encoding [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=s_encoding&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=s_encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from arpym.tools.logo import add_logo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=s_encoding-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "n_samples = 2000  # number of samples\n",
    "mu_z = np.zeros(2)  # expectation\n",
    "sigma2_z = np.array([[1, 0], [0, 1]])  # covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1](https://www.arpm.co/lab/redirect.php?permalink=s_encoding-implementation-step01): Define features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def muf(z1, z2):\n",
    "    return z1 - np.tanh(10*z1*z2)\n",
    "\n",
    "\n",
    "def sigf(z1, z2):\n",
    "    return 0  # np.sqrt(np.minimum(z1**2, 1/(10*np.pi)))\n",
    "\n",
    "\n",
    "z = np.random.multivariate_normal(mu_z, sigma2_z, n_samples)\n",
    "\n",
    "x = muf(z[:, 0], z[:, 1]) +\\\n",
    "       sigf(z[:, 0], z[:, 1]) * np.random.randn(n_samples)\n",
    "\n",
    "q_z1_15 = np.percentile(z[:, 0], 1/5*100)\n",
    "q_z1_25 = np.percentile(z[:, 0], 2/5*100)\n",
    "q_z1_35 = np.percentile(z[:, 0], 3/5*100)\n",
    "q_z1_45 = np.percentile(z[:, 0], 4/5*100)\n",
    "q_z1 = [q_z1_15, q_z1_25, q_z1_35, q_z1_45]\n",
    "c_z1 = len(q_z1)+1\n",
    "\n",
    "q_z2_16 = np.percentile(z[:, 1], 1/6*100)\n",
    "q_z2_26 = np.percentile(z[:, 1], 2/6*100)\n",
    "q_z2_36 = np.percentile(z[:, 1], 3/6*100)\n",
    "q_z2_46 = np.percentile(z[:, 1], 4/6*100)\n",
    "q_z2_56 = np.percentile(z[:, 1], 5/6*100)\n",
    "q_z2 = [q_z2_16, q_z2_26, q_z2_36, q_z2_46, q_z2_56]\n",
    "c_z2 = len(q_z2)+1\n",
    "\n",
    "z1 = np.ones(n_samples)\n",
    "z1[z[:, 0] <= q_z1[0]] = 0\n",
    "z1[np.logical_and(z[:, 0] > q_z1[0], z[:, 0] <= q_z1[1])] = 1\n",
    "z1[np.logical_and(z[:, 0] > q_z1[1], z[:, 0] <= q_z1[2])] = 2\n",
    "z1[np.logical_and(z[:, 0] > q_z1[2], z[:, 0] <= q_z1[3])] = 3\n",
    "z1[z[:, 0] > q_z1[3]] = 4\n",
    "\n",
    "z2 = np.ones(n_samples)\n",
    "z2[z[:, 1] <= q_z2[0]] = 0\n",
    "z2[np.logical_and(z[:, 1] > q_z2[0], z[:, 1] <= q_z2[1])] = 1\n",
    "z2[np.logical_and(z[:, 1] > q_z2[1], z[:, 1] <= q_z2[2])] = 2\n",
    "z2[np.logical_and(z[:, 1] > q_z2[2], z[:, 1] <= q_z2[3])] = 3\n",
    "z2[np.logical_and(z[:, 1] > q_z2[3], z[:, 1] <= q_z2[4])] = 4\n",
    "z2[z[:, 1] > q_z2[4]] = 5\n",
    "\n",
    "z = np.c_[z1, z2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2](https://www.arpm.co/lab/redirect.php?permalink=s_encoding-implementation-step02): Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "z_cat = enc.fit_transform(z).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3](https://www.arpm.co/lab/redirect.php?permalink=s_encoding-implementation-step03): Fit a regression model turning on encoded features one by one and compute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.zeros(z_cat.shape[1]+1)\n",
    "\n",
    "for l in range(z_cat.shape[1]):\n",
    "    reg = linear_model.LinearRegression()\n",
    "    x_hat = reg.fit(z_cat[:, :l+1], x).predict(z_cat[:, :l+1])\n",
    "    error[l] = np.mean((x-x_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4](https://www.arpm.co/lab/redirect.php?permalink=s_encoding-implementation-step04): Add interactions and compute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cat_inter = np.zeros((n_samples, c_z1*c_z2))\n",
    "k = 0\n",
    "for k1 in range(c_z1):\n",
    "    for k2 in range(c_z2):\n",
    "        z_cat_inter[:, k] = z_cat[:, k1]*z_cat[:, c_z1+k2]\n",
    "        k = k+1\n",
    "\n",
    "\n",
    "x_hat = reg.fit(z_cat_inter, x).predict(z_cat_inter)\n",
    "error[-1] = np.mean((x-x_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('arpm')\n",
    "\n",
    "lightblue = [0.2, 0.6, 1]\n",
    "lightgreen = [0.6, 0.8, 0]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# Error\n",
    "ax1 = plt.subplot2grid((3, 4), (0, 0), colspan=4)\n",
    "ax1.plot(1+np.arange(error.shape[0]), error, color='k')\n",
    "ax1.set_xticks(1+np.arange(error.shape[0]))\n",
    "ax1.set_xticklabels(['1 feat.', '2 feats.', '3 feats.', '4 feats.', '5 feats.',\n",
    "                     '6 feats.', '7 feats.', '8 feats.', '9 feats.',\n",
    "                     '10 feats.', '11 feats.', '2Â° ord. inter.'])\n",
    "ax1.set_title('Error', fontweight='bold')\n",
    "ax1.grid(False)\n",
    "\n",
    "# Data\n",
    "ax2 = plt.subplot2grid((3, 4), (1, 0), colspan=2, rowspan=2, projection='3d')\n",
    "ax2.scatter3D(z[:, 0], z[:, 1], x, s=10, color=lightblue, alpha=1,\n",
    "              label='$(Z_1, Z_2, X)$')\n",
    "ax2.set_xlabel('$Z_1$')\n",
    "ax2.set_xticks(np.arange(c_z1))\n",
    "ax2.set_xticklabels(['1a', '1b', '1c', '1d', '1e'])\n",
    "ax2.set_ylabel('$Z_2$')\n",
    "ax2.set_yticks(np.arange(c_z2))\n",
    "ax2.set_yticklabels(['2a', '2b', '2c', '2d', '2e', '2f'])\n",
    "ax2.set_zlabel('$X$')\n",
    "ax2.set_title('$(Z_1,Z_2,X)$', fontweight='bold')\n",
    "# ax.legend()\n",
    "\n",
    "# Fitted data\n",
    "ax3 = plt.subplot2grid((3, 4), (1, 2), colspan=2, rowspan=2, projection='3d')\n",
    "ax3.scatter3D(z[:, 0], z[:, 1], x_hat, s=15, color=lightgreen, alpha=1,\n",
    "              label='$(Z_1,Z_2, \\hat{X})$')\n",
    "ax3.set_xlabel('$Z_1$')\n",
    "ax3.set_xticks(np.arange(c_z1))\n",
    "ax3.set_xticklabels(['1a', '1b', '1c', '1d', '1e'])\n",
    "ax3.set_ylabel('$Z_2$')\n",
    "ax3.set_yticks(np.arange(c_z2))\n",
    "ax3.set_yticklabels(['2a', '2b', '2c', '2d', '2e', '2f'])\n",
    "ax3.set_zlabel('$\\hat{X}$')\n",
    "ax3.set_title('$(Z_1,Z_2,\\hat{X})$', fontweight='bold')\n",
    "# ax.legend()\n",
    "add_logo(fig, size_frac_x=1/8)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S_CMBootJoin [<img src=\"https://www.arpm.co/lab/icons/icon_permalink.png\" width=30 height=30 style=\"display: inline;\">](https://www.arpm.co/lab/redirect.php?code=S_CMBootJoin&codeLang=Python)\n",
    "For details, see [here](https://www.arpm.co/lab/redirect.php?permalink=eb-hyb-mchist-proj-vue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "sys.path.append(path.abspath('../../functions-legacy'))\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange, zeros, argsort, squeeze, \\\n",
    "    diag, eye, abs, log, exp, sqrt, newaxis, r_, array\n",
    "from numpy import sum as npsum\n",
    "from numpy.linalg import solve, pinv\n",
    "\n",
    "from scipy.stats import t\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from CONFIG import GLOBAL_DB, TEMPORARY_DB\n",
    "from intersect_matlab import intersect\n",
    "from FactorAnalysis import FactorAnalysis\n",
    "from MaxLikelihoodFPLocDispT import MaxLikelihoodFPLocDispT\n",
    "from ConditionalFP import ConditionalFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Input parameters](https://www.arpm.co/lab/redirect.php?permalink=S_CMBootJoin-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_joint = 5\n",
    "tauHL_smoo = 30  # half-life time for smoothing\n",
    "tauHL_scor = 100  # half-life time for scoring\n",
    "\n",
    "alpha = 0.25\n",
    "tauHL_prior = 21*4  # parameters for Flexible Probabilities conditioned on VIX\n",
    "\n",
    "nu_vec = range(2,31)\n",
    "nu_ = len(nu_vec)\n",
    "\n",
    "k_ = 15  # number of factors for factor analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_GARCHDCCMCProj'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_GARCHDCCMCProj'), squeeze_me=True)\n",
    "\n",
    "dates_stocks = db['dates_stocks']\n",
    "epsi_stocks = db['epsi_stocks']\n",
    "U_stocks_hor = db['U_stocks_hor']\n",
    "nu_marg = db['nu_marg']\n",
    "mu_marg = db['mu_marg']\n",
    "sig2_marg = db['sig2_marg']\n",
    "\n",
    "try:\n",
    "    db = loadmat(os.path.join(GLOBAL_DB, 'db_HistBootstrappingProj'), squeeze_me=True)\n",
    "except FileNotFoundError:\n",
    "    db = loadmat(os.path.join(TEMPORARY_DB, 'db_HistBootstrappingProj'), squeeze_me=True)\n",
    "\n",
    "epsi_SPX = db['epsi_SPX'].reshape(1,-1)\n",
    "dates_zvix = db['dates_zvix']\n",
    "dates_SPX = db['dates_SPX']\n",
    "z_vix = db['z_vix']\n",
    "nu_marg_SPX = db['nu_marg_SPX']\n",
    "mu_marg_SPX = db['mu_marg_SPX']\n",
    "sig2_marg_SPX = db['sig2_marg_SPX']\n",
    "if db['U_SPX_hor'].ndim == 2:\n",
    "    U_SPX_hor = db['U_SPX_hor'][newaxis,...]\n",
    "else:\n",
    "    U_SPX_hor = db['U_SPX_hor']\n",
    "# ## Intersect the times series of the one-step invariants and of the conditioning variable\n",
    "\n",
    "[dates_epsi, tau_stocks, tau_SPX] = intersect(dates_stocks, dates_SPX)\n",
    "epsi_stocks = epsi_stocks[:, tau_stocks]\n",
    "epsi_SPX = epsi_SPX[:, tau_SPX]\n",
    "epsi = r_[epsi_SPX, epsi_stocks]\n",
    "_, tau_vix, tau_epsi = intersect(dates_zvix, dates_epsi)\n",
    "z_vix_cond = z_vix[tau_vix]\n",
    "epsi = epsi[:, tau_epsi]\n",
    "\n",
    "i_, t_ = epsi.shape\n",
    "i_stocks, _ = epsi_stocks.shape\n",
    "i_SPX, _ = epsi_SPX.reshape(1,-1).shape\n",
    "_, m_, j_ = U_stocks_hor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the joint correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flexible probabilities\n",
    "z_vix_star = z_vix_cond[-1]  # target value\n",
    "prior = exp(-log(2) / tauHL_prior*abs(arange(t_, 1 + -1, -1)))\n",
    "prior = prior / npsum(prior)\n",
    "# conditioner\n",
    "conditioner = namedtuple('conditioner', ['Series', 'TargetValue', 'Leeway'])\n",
    "conditioner.Series = z_vix_cond.reshape(1,-1)\n",
    "conditioner.TargetValue = np.atleast_2d(z_vix_star)\n",
    "conditioner.Leeway = alpha\n",
    "p = ConditionalFP(conditioner, prior)\n",
    "\n",
    "# map invariants into student t realizations\n",
    "nu_marg = r_[nu_marg, nu_marg_SPX]\n",
    "mu_marg = r_[mu_marg, mu_marg_SPX]\n",
    "sig2_marg = r_[sig2_marg, sig2_marg_SPX]\n",
    "epsi_tilde = zeros((i_,t_))\n",
    "for i in range(i_):\n",
    "    u=t.cdf((epsi[i,:]-mu_marg[i]) / sqrt(sig2_marg[i]), nu_marg[i])\n",
    "    epsi_tilde[i,:]=t.ppf(u, nu_joint)\n",
    "\n",
    "# estimate joint correlation\n",
    "_, sig2,_ = MaxLikelihoodFPLocDispT(epsi_tilde, p, nu_joint, 10 ** -6, 1)\n",
    "c = np.diagflat(diag(sig2) ** (-1 / 2))@sig2@np.diagflat(diag(sig2) ** (-1 / 2))\n",
    "\n",
    "# replace the correlation block related to stocks with its low-rank-diagonal\n",
    "# approximation\n",
    "c_stocks, beta_stocks,*_ = FactorAnalysis(c[i_SPX:i_SPX + i_stocks, i_SPX:i_SPX+ i_stocks], array([[0]]), k_)\n",
    "c_stocks, beta_stocks = np.real(c_stocks),np.real(beta_stocks)\n",
    "c_SPX_stocks = c[:i_SPX, i_SPX :i_SPX + i_stocks]\n",
    "c_SPX = c[:i_SPX, :i_SPX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Hybrid Monte-Carlo historical projection on the grades for each node path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epsistocks_tilde_hor = zeros((i_stocks, U_stocks_hor.shape[2]))\n",
    "EpsiSPX_tilde_hor = zeros((i_SPX, U_SPX_hor.shape[2]))\n",
    "Ujoint_hor = zeros((i_,m_,j_))\n",
    "for m in trange(m_):\n",
    "    Ujoint_hor_node=zeros((i_, j_))\n",
    "    # map projected grades into standard Student t realizations\n",
    "    for i in range(i_stocks):\n",
    "        Epsistocks_tilde_hor[i,:]=squeeze(t.ppf(U_stocks_hor[i, m,:], nu_joint))\n",
    "\n",
    "    for i in range(i_SPX):\n",
    "        EpsiSPX_tilde_hor[i,:]=squeeze(t.ppf(U_SPX_hor[i, m, :], nu_joint))\n",
    "\n",
    "    # conditional historical expectation\n",
    "    m_SPX = zeros((i_SPX, j_))\n",
    "\n",
    "    # inverse stocks's correlation matrix from binomial theorem\n",
    "    delta2 = diag(eye(i_stocks) - beta_stocks@beta_stocks.T)\n",
    "    omega2 = np.diagflat(1 / delta2)\n",
    "    c_stocks_inv = omega2 - omega2@beta_stocks.dot(pinv(beta_stocks.T@omega2@beta_stocks + eye(k_)))@beta_stocks.T@omega2\n",
    "\n",
    "    m_SPX = c_SPX_stocks@c_stocks_inv@Epsistocks_tilde_hor\n",
    "\n",
    "    # Squared Mahalanobis distances\n",
    "    d = zeros(j_)\n",
    "    for j in range(j_):\n",
    "        d[j]=Epsistocks_tilde_hor[:,j].T@c_stocks_inv@Epsistocks_tilde_hor[:, j]\n",
    "\n",
    "    j_sorted_stocks = argsort(d)[::-1]  # sort indexes accordind to d\n",
    "\n",
    "    J = arange(j_)\n",
    "\n",
    "    for j in range(j_):\n",
    "        # index of the SPX's scenarios having greatest\n",
    "        # observation wrt the corresponding conditional expectation\n",
    "        d2=zeros((1, len(J)))\n",
    "        for jj in range(len(J)):\n",
    "            d2[0,jj]=solve(np.atleast_2d(EpsiSPX_tilde_hor[:,J[jj]]-m_SPX[:, j_sorted_stocks[j]]).T,c_SPX)@(EpsiSPX_tilde_hor[:, J[jj]]-m_SPX[:, j_sorted_stocks[j]])\n",
    "\n",
    "        perm_j = argsort(d2[0])[::-1]\n",
    "        j_SPX = J[perm_j[0]]\n",
    "\n",
    "        # joint projected scenarios for the invariants' grades\n",
    "        for i in range(i_SPX):\n",
    "            Ujoint_hor_node[i, j_sorted_stocks[j]]=t.cdf(EpsiSPX_tilde_hor[i, j_SPX], nu_joint)\n",
    "\n",
    "        for i in range(i_stocks):\n",
    "            Ujoint_hor_node[i+i_SPX, j_sorted_stocks[j]]=t.cdf(Epsistocks_tilde_hor[i, j_sorted_stocks[j]], nu_joint)\n",
    "\n",
    "        # discard index perm_j\n",
    "        np.delete(J, perm_j[0])\n",
    "    Ujoint_hor[:,m,:]=Ujoint_hor_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the projected joint paths scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epsi_hor = zeros((i_,m_, Ujoint_hor.shape[2]))\n",
    "for m in range(m_):\n",
    "    for i in range(i_):\n",
    "        Epsi_hor[i, m,:]=mu_marg[i] + sqrt(sig2_marg[i])*t.ppf(Ujoint_hor[i, m,:], nu_marg[i])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "executable": "/usr/bin/env python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
